{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results of\n",
    "\n",
    "\n",
    "MODEL_1 and 3 <br>\n",
    "CLASSIFIED WITH WORDS ONLY(NOT PHRASE)<br>\n",
    "ngram = 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import logging\n",
    "import numpy as np\n",
    "from optparse import OptionParser\n",
    "import sys\n",
    "from time import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB, ComplementNB, MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neighbors import NearestCentroid\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.utils.extmath import density\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "import re\n",
    "import itertools\n",
    "import os.path\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_numbers(ing):\n",
    "    # remove numbers from ingredients\n",
    "    \n",
    "    return [[re.sub(\"\\d+\", \"\", x) for x in y] for y in ing]\n",
    "\n",
    "    \n",
    "def remove_special_chars(ing):\n",
    "    # remove certain special characters from ingredients\n",
    "   \n",
    "    ing = [[x.replace(\"-\", \" \") for x in y] for y in ing] \n",
    "    ing = [[x.replace(\"&\", \" \") for x in y] for y in ing] \n",
    "    ing = [[x.replace(\"'\", \" \") for x in y] for y in ing] \n",
    "    ing = [[x.replace(\"''\", \" \") for x in y] for y in ing] \n",
    "    ing = [[x.replace(\"%\", \" \") for x in y] for y in ing] \n",
    "    ing = [[x.replace(\"!\", \" \") for x in y] for y in ing] \n",
    "    ing = [[x.replace(\"(\", \" \") for x in y] for y in ing] \n",
    "    ing = [[x.replace(\")\", \" \") for x in y] for y in ing] \n",
    "    ing = [[x.replace(\"/\", \" \") for x in y] for y in ing] \n",
    "    ing = [[x.replace(\"/\", \" \") for x in y] for y in ing] \n",
    "    ing = [[x.replace(\",\", \" \") for x in y] for y in ing] \n",
    "    ing = [[x.replace(\".\", \" \") for x in y] for y in ing] \n",
    "    ing = [[x.replace(u\"\\u2122\", \" \") for x in y] for y in ing] \n",
    "    ing = [[x.replace(u\"\\u00AE\", \" \") for x in y] for y in ing] \n",
    "    ing = [[x.replace(u\"\\u2019\", \" \") for x in y] for y in ing] \n",
    "\n",
    "    return ing\n",
    "    \n",
    "    \n",
    "def make_lowercase(ing):\n",
    "    # make all letters lowercase for all ingredients\n",
    "    \n",
    "    return [[x.lower() for x in y] for y in ing]\n",
    "    \n",
    "    \n",
    "def remove_extra_whitespace(ing):\n",
    "    # removes extra whitespaces\n",
    "    \n",
    "    return [[re.sub( '\\s+', ' ', x).strip() for x in y] for y in ing] \n",
    "    \n",
    "    \n",
    "def stem_words(ing):\n",
    "    # word stemming for ingredients\n",
    "    \n",
    "    lmtzr = WordNetLemmatizer()\n",
    "    \n",
    "    def word_by_word(strng):\n",
    "        \n",
    "        return \" \".join([\"\".join(lmtzr.lemmatize(w)) for w in strng.split()])\n",
    "    \n",
    "    return [[word_by_word(x) for x in y] for y in ing] \n",
    "    \n",
    "    \n",
    "def remove_units(ing):\n",
    "    # remove certain words from ingredients\n",
    "    \n",
    "    remove_list = ['g', 'lb', 's', 'n']\n",
    "        \n",
    "    def check_word(strng):\n",
    "        \n",
    "        s = strng.split()\n",
    "        resw  = [word for word in s if word.lower() not in remove_list]\n",
    "        \n",
    "        return ' '.join(resw)\n",
    "\n",
    "    return [[check_word(x) for x in y] for y in ing] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### by all the words\n",
    "\n",
    "df=pd.read_json('./train.json')\n",
    "X = df['ingredients'].values\n",
    "Y = df['cuisine'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = make_lowercase(X)           # 소문자로 변환\n",
    "X = remove_numbers(X)           # 숫자 제거 \n",
    "X = remove_special_chars(X)     # 특수 문자제거\n",
    "X = remove_extra_whitespace(X)  # 추가 공백 제거\n",
    "X = remove_units(X)             # ['g', 'lb', 's', 'n'] 와 같은 단위 제거\n",
    "X = stem_words(X)               # Lemmatization(원형화) nltk를 활용한 WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ingredients_preprocessed'] = X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ingredients_as_sentence'] = df['ingredients_preprocessed'].apply(', '.join)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['ingredients_as_sentence'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1, 2))\n",
    "X = vectorizer.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31819, 76243) (7955, 76243) (31819,) (7955,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2 ,random_state=2019, stratify = Y )\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark(clf):\n",
    "    print('_' * 80)\n",
    "    print(\"Training: \")\n",
    "    print(clf)\n",
    "    t0 = time()\n",
    "    clf.fit(X_train, y_train)\n",
    "    train_time = time() - t0\n",
    "    print(\"train time: %0.3fs\" % train_time)\n",
    "\n",
    "    t0 = time()\n",
    "    pred = clf.predict(X_test)\n",
    "    test_time = time() - t0\n",
    "    print(\"test time:  %0.3fs\" % test_time)\n",
    "\n",
    "    score = metrics.accuracy_score(y_test, pred)\n",
    "    print(\"accuracy:   %0.3f\" % score)\n",
    "    \n",
    "    if hasattr(clf, 'coef_'):\n",
    "        print(\"dimensionality: %d\" % clf.coef_.shape[1])\n",
    "        print(\"density: %f\" % density(clf.coef_))\n",
    "        \n",
    "    print(\"classification report:\")\n",
    "    print(metrics.classification_report(y_test, pred,target_names=target_names))\n",
    "    \n",
    "    \n",
    "    #if opts.print_cm:\n",
    "    #print(\"confusion matrix:\")\n",
    "    #print(metrics.confusion_matrix(y_test, pred))\n",
    "\n",
    "    print()\n",
    "    clf_descr = str(clf).split('(')[0]\n",
    "    return clf_descr, score, train_time, test_time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Ridge Classifier\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,\n",
      "        max_iter=None, normalize=False, random_state=2019, solver='sag',\n",
      "        tol=0.01)\n",
      "train time: 4.731s\n",
      "test time:  0.010s\n",
      "accuracy:   0.780\n",
      "dimensionality: 76243\n",
      "density: 0.892659\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   brazilian       0.82      0.49      0.62        93\n",
      "     british       0.69      0.34      0.45       161\n",
      "cajun_creole       0.79      0.66      0.72       309\n",
      "     chinese       0.77      0.90      0.83       535\n",
      "    filipino       0.81      0.50      0.61       151\n",
      "      french       0.59      0.65      0.62       529\n",
      "       greek       0.81      0.69      0.74       235\n",
      "      indian       0.83      0.90      0.86       601\n",
      "       irish       0.73      0.36      0.48       133\n",
      "     italian       0.78      0.91      0.84      1568\n",
      "    jamaican       0.80      0.58      0.67       105\n",
      "    japanese       0.89      0.68      0.77       284\n",
      "      korean       0.82      0.64      0.72       166\n",
      "     mexican       0.88      0.93      0.90      1288\n",
      "    moroccan       0.88      0.73      0.80       164\n",
      "     russian       0.68      0.33      0.44        98\n",
      " southern_us       0.70      0.80      0.75       864\n",
      "     spanish       0.79      0.44      0.56       198\n",
      "        thai       0.78      0.82      0.80       308\n",
      "  vietnamese       0.76      0.52      0.62       165\n",
      "\n",
      "   micro avg       0.78      0.78      0.78      7955\n",
      "   macro avg       0.78      0.64      0.69      7955\n",
      "weighted avg       0.78      0.78      0.77      7955\n",
      "\n",
      "\n",
      "================================================================================\n",
      "Perceptron\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "Perceptron(alpha=0.0001, class_weight=None, early_stopping=False, eta0=1.0,\n",
      "      fit_intercept=True, max_iter=50, n_iter=None, n_iter_no_change=5,\n",
      "      n_jobs=None, penalty=None, random_state=2019, shuffle=True,\n",
      "      tol=0.001, validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "train time: 0.750s\n",
      "test time:  0.012s\n",
      "accuracy:   0.750\n",
      "dimensionality: 76243\n",
      "density: 0.133021\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   brazilian       0.60      0.58      0.59        93\n",
      "     british       0.50      0.31      0.38       161\n",
      "cajun_creole       0.67      0.65      0.66       309\n",
      "     chinese       0.76      0.81      0.78       535\n",
      "    filipino       0.53      0.54      0.53       151\n",
      "      french       0.60      0.54      0.57       529\n",
      "       greek       0.73      0.67      0.70       235\n",
      "      indian       0.84      0.86      0.85       601\n",
      "       irish       0.46      0.55      0.50       133\n",
      "     italian       0.79      0.85      0.82      1568\n",
      "    jamaican       0.71      0.62      0.66       105\n",
      "    japanese       0.75      0.72      0.73       284\n",
      "      korean       0.73      0.71      0.72       166\n",
      "     mexican       0.89      0.90      0.90      1288\n",
      "    moroccan       0.82      0.78      0.80       164\n",
      "     russian       0.45      0.42      0.43        98\n",
      " southern_us       0.73      0.72      0.73       864\n",
      "     spanish       0.57      0.49      0.53       198\n",
      "        thai       0.75      0.80      0.77       308\n",
      "  vietnamese       0.62      0.57      0.59       165\n",
      "\n",
      "   micro avg       0.75      0.75      0.75      7955\n",
      "   macro avg       0.68      0.65      0.66      7955\n",
      "weighted avg       0.75      0.75      0.75      7955\n",
      "\n",
      "\n",
      "================================================================================\n",
      "Passive-Aggressive\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "PassiveAggressiveClassifier(C=1.0, average=False, class_weight=None,\n",
      "              early_stopping=False, fit_intercept=True, loss='hinge',\n",
      "              max_iter=50, n_iter=None, n_iter_no_change=5, n_jobs=None,\n",
      "              random_state=2019, shuffle=True, tol=0.001,\n",
      "              validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "train time: 1.417s\n",
      "test time:  0.012s\n",
      "accuracy:   0.769\n",
      "dimensionality: 76243\n",
      "density: 0.308225\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   brazilian       0.75      0.59      0.66        93\n",
      "     british       0.52      0.40      0.45       161\n",
      "cajun_creole       0.71      0.66      0.68       309\n",
      "     chinese       0.78      0.83      0.81       535\n",
      "    filipino       0.63      0.55      0.59       151\n",
      "      french       0.59      0.63      0.61       529\n",
      "       greek       0.74      0.70      0.72       235\n",
      "      indian       0.86      0.88      0.87       601\n",
      "       irish       0.57      0.49      0.53       133\n",
      "     italian       0.81      0.85      0.83      1568\n",
      "    jamaican       0.77      0.66      0.71       105\n",
      "    japanese       0.78      0.72      0.75       284\n",
      "      korean       0.75      0.71      0.73       166\n",
      "     mexican       0.91      0.91      0.91      1288\n",
      "    moroccan       0.80      0.78      0.79       164\n",
      "     russian       0.50      0.43      0.46        98\n",
      " southern_us       0.71      0.77      0.74       864\n",
      "     spanish       0.61      0.49      0.54       198\n",
      "        thai       0.79      0.79      0.79       308\n",
      "  vietnamese       0.65      0.59      0.62       165\n",
      "\n",
      "   micro avg       0.77      0.77      0.77      7955\n",
      "   macro avg       0.71      0.67      0.69      7955\n",
      "weighted avg       0.77      0.77      0.77      7955\n",
      "\n",
      "\n",
      "================================================================================\n",
      "kNN\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=None, n_neighbors=10, p=2,\n",
      "           weights='uniform')\n",
      "train time: 0.046s\n",
      "test time:  10.847s\n",
      "accuracy:   0.717\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   brazilian       0.60      0.46      0.52        93\n",
      "     british       0.45      0.25      0.32       161\n",
      "cajun_creole       0.69      0.64      0.67       309\n",
      "     chinese       0.67      0.88      0.76       535\n",
      "    filipino       0.62      0.47      0.53       151\n",
      "      french       0.51      0.60      0.55       529\n",
      "       greek       0.68      0.60      0.64       235\n",
      "      indian       0.83      0.83      0.83       601\n",
      "       irish       0.57      0.37      0.45       133\n",
      "     italian       0.70      0.88      0.78      1568\n",
      "    jamaican       0.82      0.50      0.62       105\n",
      "    japanese       0.85      0.58      0.69       284\n",
      "      korean       0.79      0.64      0.71       166\n",
      "     mexican       0.83      0.86      0.84      1288\n",
      "    moroccan       0.79      0.61      0.69       164\n",
      "     russian       0.71      0.15      0.25        98\n",
      " southern_us       0.69      0.70      0.69       864\n",
      "     spanish       0.68      0.33      0.44       198\n",
      "        thai       0.82      0.73      0.77       308\n",
      "  vietnamese       0.83      0.45      0.58       165\n",
      "\n",
      "   micro avg       0.72      0.72      0.72      7955\n",
      "   macro avg       0.71      0.58      0.62      7955\n",
      "weighted avg       0.72      0.72      0.71      7955\n",
      "\n",
      "\n",
      "================================================================================\n",
      "Random forest\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=None,\n",
      "            oob_score=False, random_state=2019, verbose=0,\n",
      "            warm_start=False)\n",
      "train time: 120.360s\n",
      "test time:  0.433s\n",
      "accuracy:   0.734\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   brazilian       0.86      0.39      0.53        93\n",
      "     british       0.84      0.17      0.28       161\n",
      "cajun_creole       0.82      0.62      0.71       309\n",
      "     chinese       0.70      0.89      0.79       535\n",
      "    filipino       0.76      0.36      0.49       151\n",
      "      french       0.60      0.50      0.54       529\n",
      "       greek       0.92      0.51      0.66       235\n",
      "      indian       0.82      0.91      0.86       601\n",
      "       irish       0.80      0.30      0.44       133\n",
      "     italian       0.66      0.92      0.77      1568\n",
      "    jamaican       0.96      0.41      0.57       105\n",
      "    japanese       0.84      0.61      0.71       284\n",
      "      korean       0.90      0.54      0.67       166\n",
      "     mexican       0.83      0.93      0.88      1288\n",
      "    moroccan       0.93      0.58      0.71       164\n",
      "     russian       0.84      0.21      0.34        98\n",
      " southern_us       0.61      0.76      0.68       864\n",
      "     spanish       0.93      0.27      0.42       198\n",
      "        thai       0.79      0.77      0.78       308\n",
      "  vietnamese       0.83      0.41      0.54       165\n",
      "\n",
      "   micro avg       0.73      0.73      0.73      7955\n",
      "   macro avg       0.81      0.55      0.62      7955\n",
      "weighted avg       0.76      0.73      0.72      7955\n",
      "\n",
      "\n",
      "================================================================================\n",
      "L2 penalty\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "LinearSVC(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=None, tol=0.001,\n",
      "     verbose=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train time: 5.626s\n",
      "test time:  0.009s\n",
      "accuracy:   0.794\n",
      "dimensionality: 76243\n",
      "density: 0.892659\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   brazilian       0.83      0.56      0.67        93\n",
      "     british       0.57      0.41      0.48       161\n",
      "cajun_creole       0.77      0.69      0.73       309\n",
      "     chinese       0.80      0.86      0.83       535\n",
      "    filipino       0.73      0.60      0.66       151\n",
      "      french       0.62      0.68      0.65       529\n",
      "       greek       0.79      0.71      0.75       235\n",
      "      indian       0.86      0.91      0.88       601\n",
      "       irish       0.74      0.47      0.57       133\n",
      "     italian       0.81      0.89      0.85      1568\n",
      "    jamaican       0.85      0.65      0.74       105\n",
      "    japanese       0.85      0.71      0.77       284\n",
      "      korean       0.80      0.73      0.76       166\n",
      "     mexican       0.90      0.93      0.92      1288\n",
      "    moroccan       0.84      0.79      0.81       164\n",
      "     russian       0.66      0.45      0.53        98\n",
      " southern_us       0.71      0.80      0.75       864\n",
      "     spanish       0.73      0.52      0.61       198\n",
      "        thai       0.81      0.82      0.82       308\n",
      "  vietnamese       0.75      0.59      0.66       165\n",
      "\n",
      "   micro avg       0.79      0.79      0.79      7955\n",
      "   macro avg       0.77      0.69      0.72      7955\n",
      "weighted avg       0.79      0.79      0.79      7955\n",
      "\n",
      "\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
      "       early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
      "       l1_ratio=0.15, learning_rate='optimal', loss='hinge', max_iter=50,\n",
      "       n_iter=None, n_iter_no_change=5, n_jobs=None, penalty='l2',\n",
      "       power_t=0.5, random_state=2019, shuffle=True, tol=None,\n",
      "       validation_fraction=0.1, verbose=0, warm_start=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ncp/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train time: 4.412s\n",
      "test time:  0.014s\n",
      "accuracy:   0.775\n",
      "dimensionality: 76243\n",
      "density: 0.217562\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   brazilian       0.80      0.44      0.57        93\n",
      "     british       0.69      0.23      0.34       161\n",
      "cajun_creole       0.74      0.69      0.72       309\n",
      "     chinese       0.75      0.89      0.82       535\n",
      "    filipino       0.77      0.48      0.59       151\n",
      "      french       0.63      0.61      0.62       529\n",
      "       greek       0.81      0.68      0.74       235\n",
      "      indian       0.82      0.92      0.87       601\n",
      "       irish       0.81      0.32      0.46       133\n",
      "     italian       0.77      0.91      0.83      1568\n",
      "    jamaican       0.86      0.62      0.72       105\n",
      "    japanese       0.85      0.67      0.75       284\n",
      "      korean       0.82      0.70      0.75       166\n",
      "     mexican       0.87      0.93      0.90      1288\n",
      "    moroccan       0.83      0.76      0.80       164\n",
      "     russian       0.72      0.37      0.49        98\n",
      " southern_us       0.68      0.79      0.73       864\n",
      "     spanish       0.82      0.37      0.51       198\n",
      "        thai       0.77      0.83      0.80       308\n",
      "  vietnamese       0.84      0.45      0.58       165\n",
      "\n",
      "   micro avg       0.78      0.78      0.78      7955\n",
      "   macro avg       0.78      0.63      0.68      7955\n",
      "weighted avg       0.78      0.78      0.76      7955\n",
      "\n",
      "\n",
      "================================================================================\n",
      "L1 penalty\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "LinearSVC(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l1', random_state=None, tol=0.001,\n",
      "     verbose=0)\n",
      "train time: 20.497s\n",
      "test time:  0.008s\n",
      "accuracy:   0.794\n",
      "dimensionality: 76243\n",
      "density: 0.013472\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   brazilian       0.77      0.54      0.63        93\n",
      "     british       0.61      0.38      0.47       161\n",
      "cajun_creole       0.75      0.70      0.73       309\n",
      "     chinese       0.79      0.87      0.83       535\n",
      "    filipino       0.70      0.56      0.62       151\n",
      "      french       0.60      0.68      0.64       529\n",
      "       greek       0.81      0.71      0.76       235\n",
      "      indian       0.87      0.91      0.89       601\n",
      "       irish       0.74      0.45      0.56       133\n",
      "     italian       0.82      0.89      0.85      1568\n",
      "    jamaican       0.84      0.69      0.75       105\n",
      "    japanese       0.85      0.72      0.78       284\n",
      "      korean       0.81      0.73      0.77       166\n",
      "     mexican       0.90      0.93      0.92      1288\n",
      "    moroccan       0.83      0.81      0.82       164\n",
      "     russian       0.66      0.41      0.50        98\n",
      " southern_us       0.71      0.80      0.75       864\n",
      "     spanish       0.73      0.49      0.59       198\n",
      "        thai       0.82      0.81      0.82       308\n",
      "  vietnamese       0.72      0.60      0.66       165\n",
      "\n",
      "   micro avg       0.79      0.79      0.79      7955\n",
      "   macro avg       0.77      0.68      0.72      7955\n",
      "weighted avg       0.79      0.79      0.79      7955\n",
      "\n",
      "\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
      "       early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
      "       l1_ratio=0.15, learning_rate='optimal', loss='hinge', max_iter=50,\n",
      "       n_iter=None, n_iter_no_change=5, n_jobs=None, penalty='l1',\n",
      "       power_t=0.5, random_state=2019, shuffle=True, tol=None,\n",
      "       validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "train time: 8.630s\n",
      "test time:  0.013s\n",
      "accuracy:   0.703\n",
      "dimensionality: 76243\n",
      "density: 0.000955\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   brazilian       0.09      0.32      0.14        93\n",
      "     british       0.92      0.07      0.13       161\n",
      "cajun_creole       0.73      0.63      0.67       309\n",
      "     chinese       0.69      0.87      0.77       535\n",
      "    filipino       0.61      0.15      0.24       151\n",
      "      french       0.59      0.39      0.47       529\n",
      "       greek       0.75      0.68      0.71       235\n",
      "      indian       0.78      0.90      0.83       601\n",
      "       irish       0.45      0.16      0.23       133\n",
      "     italian       0.73      0.90      0.81      1568\n",
      "    jamaican       0.83      0.33      0.48       105\n",
      "    japanese       0.86      0.60      0.71       284\n",
      "      korean       0.83      0.40      0.54       166\n",
      "     mexican       0.86      0.92      0.89      1288\n",
      "    moroccan       0.75      0.62      0.68       164\n",
      "     russian       0.41      0.16      0.23        98\n",
      " southern_us       0.63      0.75      0.68       864\n",
      "     spanish       0.54      0.14      0.22       198\n",
      "        thai       0.67      0.81      0.73       308\n",
      "  vietnamese       0.42      0.18      0.25       165\n",
      "\n",
      "   micro avg       0.70      0.70      0.70      7955\n",
      "   macro avg       0.66      0.50      0.52      7955\n",
      "weighted avg       0.71      0.70      0.68      7955\n",
      "\n",
      "\n",
      "================================================================================\n",
      "Elastic-Net penalty\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
      "       early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
      "       l1_ratio=0.15, learning_rate='optimal', loss='hinge', max_iter=50,\n",
      "       n_iter=None, n_iter_no_change=5, n_jobs=None, penalty='elasticnet',\n",
      "       power_t=0.5, random_state=2019, shuffle=True, tol=None,\n",
      "       validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "train time: 12.050s\n",
      "test time:  0.013s\n",
      "accuracy:   0.757\n",
      "dimensionality: 76243\n",
      "density: 0.016828\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   brazilian       0.65      0.34      0.45        93\n",
      "     british       0.42      0.12      0.18       161\n",
      "cajun_creole       0.74      0.69      0.71       309\n",
      "     chinese       0.73      0.89      0.80       535\n",
      "    filipino       0.76      0.39      0.52       151\n",
      "      french       0.63      0.57      0.60       529\n",
      "       greek       0.79      0.66      0.72       235\n",
      "      indian       0.80      0.92      0.85       601\n",
      "       irish       0.69      0.28      0.40       133\n",
      "     italian       0.75      0.91      0.83      1568\n",
      "    jamaican       0.87      0.55      0.67       105\n",
      "    japanese       0.84      0.66      0.74       284\n",
      "      korean       0.83      0.63      0.72       166\n",
      "     mexican       0.86      0.94      0.90      1288\n",
      "    moroccan       0.84      0.74      0.79       164\n",
      "     russian       0.63      0.19      0.30        98\n",
      " southern_us       0.65      0.80      0.71       864\n",
      "     spanish       0.76      0.25      0.38       198\n",
      "        thai       0.74      0.81      0.78       308\n",
      "  vietnamese       0.86      0.38      0.53       165\n",
      "\n",
      "   micro avg       0.76      0.76      0.76      7955\n",
      "   macro avg       0.74      0.59      0.63      7955\n",
      "weighted avg       0.75      0.76      0.74      7955\n",
      "\n",
      "\n",
      "================================================================================\n",
      "NearestCentroid (aka Rocchio classifier)\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "NearestCentroid(metric='euclidean', shrink_threshold=None)\n",
      "train time: 0.068s\n",
      "test time:  0.015s\n",
      "accuracy:   0.625\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   brazilian       0.25      0.48      0.33        93\n",
      "     british       0.19      0.45      0.27       161\n",
      "cajun_creole       0.54      0.72      0.62       309\n",
      "     chinese       0.82      0.71      0.76       535\n",
      "    filipino       0.32      0.57      0.41       151\n",
      "      french       0.41      0.46      0.43       529\n",
      "       greek       0.56      0.65      0.60       235\n",
      "      indian       0.87      0.73      0.79       601\n",
      "       irish       0.35      0.56      0.43       133\n",
      "     italian       0.89      0.60      0.72      1568\n",
      "    jamaican       0.56      0.51      0.53       105\n",
      "    japanese       0.78      0.58      0.67       284\n",
      "      korean       0.54      0.64      0.59       166\n",
      "     mexican       0.93      0.77      0.84      1288\n",
      "    moroccan       0.55      0.78      0.64       164\n",
      "     russian       0.31      0.51      0.39        98\n",
      " southern_us       0.67      0.47      0.55       864\n",
      "     spanish       0.22      0.64      0.33       198\n",
      "        thai       0.78      0.57      0.66       308\n",
      "  vietnamese       0.47      0.65      0.55       165\n",
      "\n",
      "   micro avg       0.62      0.62      0.62      7955\n",
      "   macro avg       0.55      0.60      0.56      7955\n",
      "weighted avg       0.71      0.62      0.65      7955\n",
      "\n",
      "\n",
      "================================================================================\n",
      "Naive Bayes\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "MultinomialNB(alpha=0.01, class_prior=None, fit_prior=True)\n",
      "train time: 0.184s\n",
      "test time:  0.009s\n",
      "accuracy:   0.745\n",
      "dimensionality: 76243\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "density: 1.000000\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   brazilian       0.72      0.54      0.62        93\n",
      "     british       0.46      0.43      0.45       161\n",
      "cajun_creole       0.62      0.72      0.66       309\n",
      "     chinese       0.75      0.85      0.80       535\n",
      "    filipino       0.72      0.54      0.62       151\n",
      "      french       0.52      0.58      0.55       529\n",
      "       greek       0.77      0.63      0.69       235\n",
      "      indian       0.86      0.88      0.87       601\n",
      "       irish       0.64      0.41      0.50       133\n",
      "     italian       0.81      0.83      0.82      1568\n",
      "    jamaican       0.77      0.52      0.62       105\n",
      "    japanese       0.86      0.62      0.72       284\n",
      "      korean       0.77      0.64      0.70       166\n",
      "     mexican       0.91      0.88      0.90      1288\n",
      "    moroccan       0.69      0.76      0.72       164\n",
      "     russian       0.55      0.38      0.45        98\n",
      " southern_us       0.62      0.73      0.67       864\n",
      "     spanish       0.59      0.47      0.52       198\n",
      "        thai       0.72      0.81      0.76       308\n",
      "  vietnamese       0.66      0.50      0.57       165\n",
      "\n",
      "   micro avg       0.74      0.74      0.74      7955\n",
      "   macro avg       0.70      0.64      0.66      7955\n",
      "weighted avg       0.75      0.74      0.74      7955\n",
      "\n",
      "\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "BernoulliNB(alpha=0.01, binarize=0.0, class_prior=None, fit_prior=True)\n",
      "train time: 0.192s\n",
      "test time:  0.066s\n",
      "accuracy:   0.722\n",
      "dimensionality: 76243\n",
      "density: 1.000000\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   brazilian       0.45      0.59      0.51        93\n",
      "     british       0.32      0.55      0.40       161\n",
      "cajun_creole       0.63      0.74      0.68       309\n",
      "     chinese       0.81      0.77      0.79       535\n",
      "    filipino       0.54      0.68      0.60       151\n",
      "      french       0.54      0.53      0.53       529\n",
      "       greek       0.65      0.68      0.66       235\n",
      "      indian       0.89      0.85      0.87       601\n",
      "       irish       0.44      0.56      0.50       133\n",
      "     italian       0.88      0.74      0.80      1568\n",
      "    jamaican       0.73      0.56      0.63       105\n",
      "    japanese       0.74      0.63      0.68       284\n",
      "      korean       0.73      0.71      0.72       166\n",
      "     mexican       0.93      0.85      0.89      1288\n",
      "    moroccan       0.68      0.78      0.73       164\n",
      "     russian       0.33      0.49      0.39        98\n",
      " southern_us       0.66      0.69      0.68       864\n",
      "     spanish       0.43      0.58      0.49       198\n",
      "        thai       0.75      0.74      0.75       308\n",
      "  vietnamese       0.60      0.55      0.57       165\n",
      "\n",
      "   micro avg       0.72      0.72      0.72      7955\n",
      "   macro avg       0.64      0.67      0.64      7955\n",
      "weighted avg       0.75      0.72      0.73      7955\n",
      "\n",
      "\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "ComplementNB(alpha=0.1, class_prior=None, fit_prior=True, norm=False)\n",
      "train time: 0.197s\n",
      "test time:  0.009s\n",
      "accuracy:   0.721\n",
      "dimensionality: 76243\n",
      "density: 1.000000\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   brazilian       0.77      0.46      0.58        93\n",
      "     british       0.57      0.22      0.32       161\n",
      "cajun_creole       0.65      0.63      0.64       309\n",
      "     chinese       0.65      0.90      0.75       535\n",
      "    filipino       0.82      0.33      0.47       151\n",
      "      french       0.60      0.50      0.55       529\n",
      "       greek       0.77      0.54      0.64       235\n",
      "      indian       0.76      0.90      0.82       601\n",
      "       irish       0.66      0.25      0.36       133\n",
      "     italian       0.75      0.89      0.82      1568\n",
      "    jamaican       0.73      0.44      0.55       105\n",
      "    japanese       0.84      0.68      0.75       284\n",
      "      korean       0.81      0.45      0.58       166\n",
      "     mexican       0.85      0.91      0.88      1288\n",
      "    moroccan       0.74      0.55      0.63       164\n",
      "     russian       0.61      0.26      0.36        98\n",
      " southern_us       0.57      0.73      0.64       864\n",
      "     spanish       0.72      0.26      0.38       198\n",
      "        thai       0.69      0.74      0.72       308\n",
      "  vietnamese       0.78      0.32      0.45       165\n",
      "\n",
      "   micro avg       0.72      0.72      0.72      7955\n",
      "   macro avg       0.72      0.55      0.59      7955\n",
      "weighted avg       0.72      0.72      0.70      7955\n",
      "\n",
      "\n",
      "================================================================================\n",
      "LinearSVC with L1-based feature selection\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "Pipeline(memory=None,\n",
      "     steps=[('feature_selection', SelectFromModel(estimator=LinearSVC(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l1', random_state=2019, tol=0.001,\n",
      "     verbose=0),\n",
      "        max_features=None, no...ax_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=2019, tol=0.0001,\n",
      "     verbose=0))])\n",
      "train time: 22.487s\n",
      "test time:  0.014s\n",
      "accuracy:   0.795\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   brazilian       0.81      0.58      0.68        93\n",
      "     british       0.59      0.40      0.48       161\n",
      "cajun_creole       0.79      0.71      0.75       309\n",
      "     chinese       0.81      0.87      0.84       535\n",
      "    filipino       0.72      0.57      0.64       151\n",
      "      french       0.61      0.66      0.63       529\n",
      "       greek       0.82      0.73      0.77       235\n",
      "      indian       0.85      0.90      0.88       601\n",
      "       irish       0.75      0.50      0.60       133\n",
      "     italian       0.81      0.89      0.85      1568\n",
      "    jamaican       0.85      0.64      0.73       105\n",
      "    japanese       0.85      0.73      0.79       284\n",
      "      korean       0.81      0.73      0.77       166\n",
      "     mexican       0.90      0.93      0.92      1288\n",
      "    moroccan       0.85      0.78      0.81       164\n",
      "     russian       0.60      0.43      0.50        98\n",
      " southern_us       0.72      0.80      0.76       864\n",
      "     spanish       0.72      0.51      0.60       198\n",
      "        thai       0.83      0.82      0.83       308\n",
      "  vietnamese       0.76      0.60      0.67       165\n",
      "\n",
      "   micro avg       0.80      0.80      0.80      7955\n",
      "   macro avg       0.77      0.69      0.72      7955\n",
      "weighted avg       0.79      0.80      0.79      7955\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "RANDOM_ST = 2019\n",
    "\n",
    "target_names = ['brazilian', 'british', 'cajun_creole', 'chinese', 'filipino', 'french', 'greek',\n",
    "           'indian', 'irish', 'italian', 'jamaican', 'japanese', 'korean', 'mexican', 'moroccan',\n",
    "           'russian', 'southern_us', 'spanish', 'thai', 'vietnamese']\n",
    "\n",
    "results = []\n",
    "for clf, name in (\n",
    "        (RidgeClassifier(tol=1e-2, solver=\"sag\",random_state=RANDOM_ST), \"Ridge Classifier\"),\n",
    "        (Perceptron(max_iter=50, tol=1e-3,random_state=RANDOM_ST), \"Perceptron\"),\n",
    "        (PassiveAggressiveClassifier(max_iter=50, tol=1e-3,random_state=RANDOM_ST), \"Passive-Aggressive\"),\n",
    "        (KNeighborsClassifier(n_neighbors=10), \"kNN\"),\n",
    "        (RandomForestClassifier(n_estimators=100,random_state=RANDOM_ST), \"Random forest\")):\n",
    "    print('=' * 80)\n",
    "    print(name)\n",
    "    results.append(benchmark(clf))\n",
    "    \n",
    "for penalty in [\"l2\", \"l1\"]:\n",
    "    print('=' * 80)\n",
    "    print(\"%s penalty\" % penalty.upper())\n",
    "    # Train Liblinear model\n",
    "    results.append(benchmark(LinearSVC(penalty=penalty, dual=False, tol=1e-3)))\n",
    "\n",
    "    # Train SGD model\n",
    "    results.append(benchmark(SGDClassifier(alpha=.0001, max_iter=50,penalty=penalty,random_state=RANDOM_ST)))\n",
    "\n",
    "# Train SGD with Elastic Net penalty\n",
    "print('=' * 80)\n",
    "print(\"Elastic-Net penalty\")\n",
    "results.append(benchmark(SGDClassifier(alpha=.0001, max_iter=50,penalty=\"elasticnet\",random_state=RANDOM_ST)))\n",
    "\n",
    "# Train NearestCentroid without threshold\n",
    "print('=' * 80)\n",
    "print(\"NearestCentroid (aka Rocchio classifier)\")\n",
    "results.append(benchmark(NearestCentroid()))\n",
    "\n",
    "# Train sparse Naive Bayes classifiers\n",
    "print('=' * 80)\n",
    "print(\"Naive Bayes\")\n",
    "results.append(benchmark(MultinomialNB(alpha=.01)))\n",
    "results.append(benchmark(BernoulliNB(alpha=.01)))\n",
    "results.append(benchmark(ComplementNB(alpha=.1)))\n",
    "\n",
    "print('=' * 80)\n",
    "print(\"LinearSVC with L1-based feature selection\")\n",
    "# The smaller C, the stronger the regularization.\n",
    "# The more regularization, the more sparsity.\n",
    "results.append(benchmark(Pipeline([('feature_selection', SelectFromModel(LinearSVC(penalty=\"l1\", dual=False,tol=1e-3,random_state=RANDOM_ST))),\n",
    "  ('classification', LinearSVC(penalty=\"l2\",random_state=RANDOM_ST))])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "def Xgboost_():\n",
    "    try:\n",
    "        pipe = Pipeline([('classifier', xgb.XGBClassifier(random_state=RANDOM_ST))])\n",
    "        hyperparameter_space = [{'classifier': [xgb.XGBClassifier()],\n",
    "                                 'classifier__max_depth': [3, 4, 5],\n",
    "                                 'classifier__n_estimators' : [350, 375, 400]}]\n",
    "        grid = GridSearchCV(pipe, hyperparameter_space, cv=3)\n",
    "        grid.fit(X_train, y_train)\n",
    "\n",
    "        cuisine = ['brazilian', 'british', 'cajun_creole', 'chinese', 'filipino', 'french', 'greek',\n",
    "                   'indian', 'irish', 'italian', 'jamaican', 'japanese', 'korean', 'mexican', 'moroccan',\n",
    "                   'russian', 'southern_us', 'spanish', 'thai', 'vietnamese']\n",
    "\n",
    "        print (classification_report(y_test, grid.predict(X_test), digits=4, target_names=cuisine))\n",
    "\n",
    "        return print(\"Best parameters:\\n{}\\n\".format(grid.best_params_), \n",
    "                     \"Best score : {}\\n\".format(grid.best_score_),\n",
    "                     \"Test score : {}\".format(grid.score(X_test, y_test)))\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xgboost_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________________________________\n",
      "Training: \n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
      "       max_depth=25, min_child_weight=1, missing=None, n_estimators=400,\n",
      "       n_jobs=1, nthread=None, objective='binary:logistic',\n",
      "       random_state=2019, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "       seed=None, silent=True, subsample=1)\n",
      "train time: 9072.071s\n",
      "test time:  20.206s\n",
      "accuracy:   0.793\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   brazilian       0.88      0.60      0.71        93\n",
      "     british       0.66      0.39      0.49       161\n",
      "cajun_creole       0.77      0.71      0.74       309\n",
      "     chinese       0.79      0.86      0.82       535\n",
      "    filipino       0.74      0.56      0.64       151\n",
      "      french       0.62      0.65      0.64       529\n",
      "       greek       0.83      0.69      0.75       235\n",
      "      indian       0.86      0.90      0.88       601\n",
      "       irish       0.71      0.47      0.56       133\n",
      "     italian       0.80      0.91      0.85      1568\n",
      "    jamaican       0.85      0.69      0.76       105\n",
      "    japanese       0.83      0.68      0.75       284\n",
      "      korean       0.85      0.67      0.75       166\n",
      "     mexican       0.91      0.94      0.92      1288\n",
      "    moroccan       0.85      0.74      0.79       164\n",
      "     russian       0.76      0.42      0.54        98\n",
      " southern_us       0.71      0.80      0.75       864\n",
      "     spanish       0.72      0.54      0.62       198\n",
      "        thai       0.79      0.81      0.80       308\n",
      "  vietnamese       0.69      0.61      0.65       165\n",
      "\n",
      "   micro avg       0.79      0.79      0.79      7955\n",
      "   macro avg       0.78      0.68      0.72      7955\n",
      "weighted avg       0.79      0.79      0.79      7955\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "# xgb  <- xgboost(xgbmat, max.depth = 25, \n",
    "# eta = 0.3, nround = 200, objective = \"multi:softmax\", num_class = 20)\n",
    "# https://www.kaggle.com/mohdatir/xgboost\n",
    "\n",
    "results.append(benchmark(xgb.XGBClassifier(max_depth=25, n_estimators=400, random_state=RANDOM_ST)))\n",
    "\n",
    "# objective='binary:logistic'  objective issue : \n",
    "# https://stackoverflow.com/questions/39386966/multiclass-classification-in-xgboost-python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "results =[('RidgeClassifier', 0.7802639849151477, 4.730539083480835, 0.010100364685058594), ('Perceptron', 0.7504714016341923, 0.749875545501709, 0.012344121932983398), ('PassiveAggressiveClassifier', 0.7693274670018856, 1.4168105125427246, 0.011583328247070312), ('KNeighborsClassifier', 0.7174104336895034, 0.04632210731506348, 10.84746503829956), ('RandomForestClassifier', 0.7338780641106223, 120.3596305847168, 0.4328477382659912), ('LinearSVC', 0.7940917661847895, 5.625608444213867, 0.008724212646484375), ('SGDClassifier', 0.7751099937146448, 4.412171363830566, 0.013699769973754883), ('LinearSVC', 0.7937146448774356, 20.497478485107422, 0.007840633392333984), ('SGDClassifier', 0.7029541169076052, 8.629814863204956, 0.013385534286499023), ('SGDClassifier', 0.7565053425518542, 12.050124883651733, 0.013379096984863281), ('NearestCentroid', 0.6248900062853551, 0.06776666641235352, 0.015046834945678711), ('MultinomialNB', 0.7449402891263356, 0.1841135025024414, 0.008781671524047852), ('BernoulliNB', 0.722438717787555, 0.19157123565673828, 0.06558728218078613), ('ComplementNB', 0.7211816467630421, 0.19689583778381348, 0.008781671524047852), ('Pipeline', 0.7952231301068511, 22.48663091659546, 0.013879060745239258), ('XGBClassifier', 0.7929604022627278, 9072.071280479431, 20.20596432685852)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = sorted(results,  key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAuMAAAIzCAYAAACqQxeLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzs3X20nWV95//3J8lpAEUrWomASEhtSQuWShalJiQh1kIYgSBM0wjRIESqDg+DzoyrVljY1tG1qqODyvBUsEgiKpox1oRWyCESqq4c4Ke0aJ2AotJSBx/K8BBD+P7+2PfBzck+OTvJSe4E3q+1ztr3vvZ1X9f3vk/++Jwr1947VYUkSZKkXW9C2wVIkiRJz1WGcUmSJKklhnFJkiSpJYZxSZIkqSWGcUmSJKklhnFJkiSpJYZxSZIkqSWGcUnSHi/J4iRfS3J7ko+3XY8k9St+6Y8kaU+WZH9gBTCnqn6RZEJVPdV2XZLUD1fGJUl7uoOB71XVLwCGg3iSVya5LclQkluHOyd5S5JvJrk7yZuattOT/HOStyb5YpJ1Sf6meW1u8/ybSc5q4fokPYu5Mi5J2qMlmQgMAp8BPlZVlWQSMAQsrapvdPU9kM4q+rFAgNuB/1BV/5pkCXAJ8AdVtaEZ93nAGuA4YCOwDnhDVT2wq65P0rObK+OSpD1aVW0GXg/MAP6+2bby+8D67iDeOAG4vqqeqKrHgRuAE7tev7WqNowY92+r6t+raiPwOeD4nXtFkp5LDOOSpD1eVf28qt4MXA18GTgA+D89ur4U+Jeu5z9q2ob984j+Lwf+OMlgkkHgdGBgvOqWpEltFyBJ0nipqk8nWUgncP+HHl1+DEzpen4A8FDX840j+v8r8DdV9RfjWqgkNVwZlyTt0ZL8SpJ9m+P9gEOArwNHJpk1ovuXgTcneV6SvYEzgVVbGf7LwMIkv9aM/7zxrl/Sc5sr45KkPd2vAV9M8gTwJHBRVW1MchpwTROgf1ZVr62qB5P8d+AfgM3Apc2bN6cDfwpMSvLrVfWfAKrqx0n+czP+U8CTSY7zoxMljRc/TUWSJElqidtUJEmSpJYYxiVJkqSWGMYlSZKklvgGTu3WXvKSl9QhhxzSdhmSJEnbZGho6P9W1a+N1c8wrt3aIYccwvr169suQ5IkaZsk+X4//dymIkmSJLXEMC5JkiS1xDAuSZIktcQ945IkSXuQTZs28cMf/pAnnnii7VIE7LXXXhx00EEMDAxs1/mGcUmSpD3ID3/4Q/bdd18OOeQQkrRdznNaVfHwww/zwx/+kKlTp27XGG5TkSRJ2oM88cQTvPjFLzaI7waS8OIXv3iH/pfCMC5JkrSHMYjvPnb0d+E2FUmSpD1Ycum4jld1ybiOp61zZVySJElqiWFckiRJaolhXJIkSdvk0Ucf5YQTTmDu3LnMnz8fgEsuuYRZs2Zx3HHH8bOf/YxHHnmE0047jblz5/KmN72JjRs3ct111zFt2jQ+/OEPM3PmTBYtWsSmTZs4++yzmTdvHosWLWLjxo0tX92uZRiXJEnSNnnooYc4/PDDGRwcZNWqVaxatYpHH32U22+/nTVr1vCrv/qrXHXVVSxcuJDBwUGOOeYYli9fzpIlS5gzZw57770369atY/ny5Vx77bW89rWv5dZbb+XEE09k+fLlbV/eLuUbOCVJkrRNDj30UN72trdx7bXXsv/++3PPPfdw6qmnPqPPd7/7Xc444wwAjjvuOK6//noAnnrqKd7whjc83e/uu+/mzjvv5Morr2TTpk2cfPLJu+5CdgOGcUmSJG2zadOmMW3aNC644AKmTZvGZz7zGWbOnPn067/5m7/J2rVr+Y//8T9y2223MX369Kdfmzx58tPH06dP5zWveQ1nnnnmLq1/d5GqarsGaVQzZsyo9evXt12GJEm7jXvvvfcZwbYNX/va13j7299OEg488EBuvPFGPvCBD/B3f/d3TJ48mRUrVjAwMMBb3vIW/u3f/o2pU6dyxRVXcMcdd7Bw4UJ+/dd/nWXLlnHwwQfzxBNPsHTpUn7wgx8wefJkPvnJTzJlypRWr29b9fqdJBmqqhljnWsY127NMC5J0jPtDmFcz7QjYdw3cEqSJEktMYxLkiRJLTGMS5IkSS0xjEuSJEktMYxLkiRJLfFzxiVJkvZgGRwc1/Fq7txxHU9b58q4JEmSttnChQu367yq4rzzzhu3fttiZM07Y45tZRiXJEnSNtu4ceN2nZeEyy67bNz6bYuRNe+MObaVYVySJEl9W7lyJXPnzuX2229n7ty5rFy5kuuuu45p06bx4Q9/mJkzZ7Jo0SKefPJJzjjjDF772tfyxje+kZ///Ods3LiRefPmMW3atKfHu+666zj33HM5/vjjOeGEE3jiiSf67vfII49w6qmnMnv2bM477zyuv/76vmvuNcc555zDggULuPjiiznyyCO57bbb2LRpE2effTbz5s1j0aJF2/1HyGgM45IkSerbSSedxODgILNmzWJwcJCTTjqJJUuWMGfOHPbee2/WrVvH8uXLmTRpEkcffTRJuPfee/nc5z7H5MmTufXWWzniiCOeMeb+++/PzTffzIknnsjf//3f993vmmuu4eyzz2bt2rU88sgjbN68ue+ae83x5JNP8uEPf5ivfOUrXH/99axatYprr72W1772tdx6662ceOKJLF++fFzvp2/glCRJ0g576qmneMMb3vD08y984Qvcf//9rFq1itWrV7Nhw4ZRz/3d3/1dAKZOncpPfvKTvvt9+9vf5owzzgDg937v98bjMthvv/146Utfyr777ssTTzzB3XffzZ133smVV17Jpk2bOPnkk8dlnmGGcUmSJG2zTZs2bdE2efLkp483bNjACSecwMDAADfccAPHHHPMqGMlefqxqvrud/DBB/P1r3+d17/+9Xzta1/juOOO2+aaxzJ9+nRe85rXcOaZZ27zuf0wjEuSJO3B2voowr333ps5c+bw7ne/m3322YfVq1fz+te/nmXLlnHwwQfzxje+kYULF/K+972PU045hYkTJ/KjH/2IM844g3vuuYe5c+dy2WWXMXHiRCZOnAjw9HG//c4991wWLVrERz7yEfbbbz9e+MIX9l3zq171qi3mmDRpEhMmTGBgYODpOZYuXcrSpUu5+uqrmTx5Mp/85CeZMmXKuN3HbO2vD6ltM2bMqPXr17ddhiRJu417772X6dOnt13GbmHz5s1MnDiRquKP/uiP+PCHP8zLX/7yXV5Hr99JkqGqmjHWub6BU5IkSXuku+++m1mzZnHssccyd+7cVoL4jnKbiiRJkvZIRx11FLfffnvbZewQV8YlSZKklhjGJUmSpJYYxiVJkqSWuGdckiRpT/ahjO947/ST9nYlV8YlSZK0zRYuXLjTzx3Zr6o477zztnve3dGYYTzJ4iSrm+P5SRbv/LKenvvGEc8XJBlKcmuSw3d0vG04L0kuG+W12UmeXf8qJEmSxrBx48adfu7Ifkm47LKekWyP1c/K+ETgoCRTmuOJO7ekZ3j6O1WTvAi4ADi2quZV1T07Mt62qI7RAvcEdu09kSRJas3KlSuZO3cut99+O3PnzmXlypVs2rSJs88+m3nz5rFo0SI2btzIo48+ygknnMDcuXOZP3/+qOf2O8fGjRuZN28e06ZNe7rfOeecw4IFC7j44os58sgjue2223rWsjsb8xs4kywBpgI/ATYALwOOadoeApYAm4FPAlOatrcBpwLvBT4OnAY8ALwJ+F8jzp0E3ATsBTxeVfOTnAS8EzgcuAf4ELAfsKmqlnXVNtBjvEXA7wOHAAUsAF7XY7wX96jvrcB1zWsPAEubqVYBr6iqac28zwc+Bfwa8E3gO1X1ka3eSG0Xv4FTkqRn2uLbHlvaM75gwQJWrFgBwJVXXsnzn/983vjGN3L99dezefNmZs+ezSc+8Qn+6q/+aqvn9jtHr7YlS5Zw8cUXc+aZZ3LFFVdwww03cOihh25Ry5IlS/q6pu21I9/A2e8bOO8CTqETxgPcUlXLmi0ri6rquiTfAE4CpgOnV9U1SWbTCdgzm6LeOvJcYC1wT1W9a3iyqloJrEyyoqoWNOe+G1gzoq6zeowH8FBVnZvkfOB1vcZrxhxZ30XAjVX1mSRvH742YF6S7n8JbwVuqKrPJtnyX5jGzdDQgySXtl2GJO0xqi5puwQ9B919993ceeedXHnllWzatImTTz6ZQw89lLe97W1ce+217L///px44ok7Ze799tuPl770pey777488cQTPWvZnW3Lp6l8F5gG/Hfgm02wHgC+mORUOqvT84ETmn7Q2cLx+a4xjgRe3X1uVd2X5PIkZ9EJ0V8eZf4HgUOBr29tPDor5Hc1r99PZ0V9NCPreyVwQ3O8Bhhtf/wr6ayMA3yVzrVLkiQ9Z2zatOnp4+nTp/Oa17yGM8888xl9pk2bxrRp07jgggs49NBDOeyww7Y4t985+jVaLburbQnjy4FlwH8DflpVw2GUJO8CVlfVpiRnAF/rOq97o869wB3d5wJU1QZgQ5KPJrmvqr7dvDTQ1W0lcFOS/11Vj402XrOtZvj/V4rOSv6w7vF61fcdYDbwWWBOM34v/9j0+xwwC/jRKP0kSZJ2rpY+inDvvfdmzpw5vPvd72bp0qUsXbqUq6++msmTJ/PJT36S733ve7z97W8nCQceeCCveMUrep47vJ98rDle9apXccYZZ3DPPfcwd+5cLrvsMiZNmsSECRMYGBhg4sSJTJw4sWctU6ZM2RW3ZLv0s2d8MfCzqlqZ5HbgCuAPgZfTCbJvprPCfCOdNzL+b+AxOnupbwT+D/DGqnogyV7AVSPOPQT4BJ3g/CNgYVU93sz9OTr7sj9QVauSnAxcDDwCnE9ntX7keK/rqnc+8JKqun7keE2NI+t7HvDXwEvprKqf2xzfwC/3m59HZ7vO8B75f6KzzebZ9dbe3URyQHV+DZKkfrhN5dmv1/5ktWtH9oyPGcalNhnGJWnbGMaf/Qzju58dCeN+6Y8kSZLUkm3ZMy7tckcddQDr17vKI0lSt6oiGeePNNR22dFdJq6MS5Ik7UH22msvHn744R0OgdpxVcXDDz/MXnvttd1juDIuSZK0BznooIP44Q9/yI9//OO2SxGdP44OOuig7T7fMC5JkrQHGRgYYOpUv+Lk2cJtKpIkSVJLDOOSJElSSwzjkiRJUksM45IkSVJLDOOSJElSSwzjkiRJUksM45IkSVJLDOOSJElSSwzjkiRJUksM45IkSVJLDOOSJElSSwzjkiRJUksM45IkSVJLDOOSJElSSwzjkiRJUksM45IkSVJLxgzjSSYnuTHJYJIvNm1vSbI+ye1JXprkvc3zu5K8uevcBUmGktya5PAk+zTH68brAtJx2Yi2CUlWJbk5yRGj9ZMkSZLaNKmPPicAd1TVRwGS/DZwMnA0UE2ficA5wD8BK5LcAjwKXAAcW1WPdY03L8mKcaqfqirgvBHNLwPuq6p3jNFPkiRJak0/21S+CfxWkoHm+WnA+6vqqWoMd6yqXwAfAd5AJ7BfNSKIbyHJpCQ3JLklybIkL0zyvCSrm9X4VU2/Xm2Tm5X2DV3jnQbcBJzS9F0wSr+BJNc07cubPkuSbEhyUZJ1SZb3cxMlSZKk7TFmGK+q+4GPAZ9IcjRwAPD9JO9P8rXubSmNB4CD6KxOb2AMVfUk8A06q+zTgdOB/YF7qmpuVc1vum7RVlUbq2oe8K2u8W4C/hj4XNN3Ra9+wFnALU37l4FFVXUdcBvweFXNrKpFY9UvSZIkba9+tqlQVd9K8lbgajph++Cq+tMkc4EjR3R/OfAw8C/AocDXtzZ2klOBqcB8OltiplXVfUkuT3IW8FBVfblXW/+X2dORwKub6xoAvti0TwA+v4Nja5wMDT1IcmnbZUiSxlnVJW2XIO0W+nkD56/A03uufwJ8BXh3ki2CfJK96OzLvhFYCSxNss8YU0wDVlfVJuCM4caq2lBV1wLHJzlstLYdcC/wsWb1fGZVfbDrtY07OLYkSZI0pn72jB+V5B+SrAUGqmodnaD9VeCDdN60uZnOqvka4Oqq+l5V/ZTO/vG1SdYkOSLJnCSDwKymbT9gGfCeJHcAdwGbkxyT5M4kQ3RWzb8/StuBXeMNDn9ySlPP5uELGKXfVXRC/WDzqStTksyhszr/pSQHb+9NlSRJkvqRrvdfSrud5ICCc9suQ5I0ztymome7JENVNWOsfn7pjyRJktQSw7gkSZLUkr4+TUVqy1FHHcD69f5XpiRJenZyZVySJElqiWFckiRJaolhXJIkSWqJYVySJElqiWFckiRJaomfpqLd20ND8KG0XYWk55p3+oV4knYNV8YlSZKklhjGJUmSpJYYxiVJkqSWGMYlSZKklhjGJUmSpJb4aSrave1/FLxzfdtVSJIk7RSujEuSJEktMYxLkiRJLTGMS5IkSS0xjEuSJEktMYxLkiRJLTGMS5IkSS0xjEuSJEktGTOMJ3l5kg81xx9IsjjJ6ub5/CSLt3Juklw2xviLk5w0ou1NI9t2VJIFSYaS3Jrk8CT7NMfrxnGOLa43yYQkq5LcnOSI0fpJkiTpuaefL/2ZCExM8rvAi5vnByWZMvzaaCdWVQHn9TP+iLYJWxt3WyV5EXABcGxVPdb10rwkK8ZrnlGu92XAfVX1jjH6SZIk6Tmm320qE4E/B/5r8/wmYOHwi0kGklzTrDQvTzK5+bk1yYaufvsm+UKStUku61pVf3OSv0vy5SR7N20nJbk9yd8m+dXm3JuSDCb5m2b8JUk2JLkoybpm7uclWd30W9WMdTJw1YggvoUkk5LckOSWJMuSvLDXeKO09bre05p7dUrTd8Eo/Xrdvy2urc/flSRJkvYQ/YbxhcALgH9vnt8FHNn1+lnALVU1D/gysKiqNjbPv9XV72zgmqqaDezLL1e/11fVHwJ/C7y+aXuyqmYBHwEuBJYCN1bVXOBrzRzXAbcBj1fVzKpaBOwP3FNVc6tqfjPWy4Cnw+9oqupJ4BtAAdOB00cZb4u2XtdbVTcBfwx8rum7YpT70uv+9bo2SZIkPYv0s00F4A7gM3TC9C+atu8C04Cf0wnmr07yVmAA+OIo4xwG3NAcf72r/R+bx38CXtWMeXvT9lU6YfXnXeeuAYZX1ScAnx8eqKruS3J5krOAh6rqy8CDwKEj5txCklOBqcB84ARgWq/xRpljR4x2/55xbc9FQ0MPklzadhmSpF2o6pK2S5B2mX5Xxr8HLAdOA57ftC2ns+oLcC/wsWb1d2ZVfXCUcR4Afq85PqbH6wWkOX5N8zgH+CbwHWB2V9u9XedtfMYgVRuq6lrg+CSHASuBpUn22dpF0vnjYnVVbQLO2Mp4Pdt2wNbu38bRTpIkSdKerZ8wvhnY3Lzp8H/SeRPn5qq6f/g14Co6oXSw+dSQKUkOTDIIzGrajwCuAM5P8hVgbzqr3cNj0HW8GZic5KvAnwAfb+Y4Pcka4Gjg00nm0FnB/lKSgwGSHJPkziRDdFa5v19VP6Wz3WVtkjVJjkgyp6u+NUn2A5YB70lyB52tOJt7jTdKW6/r7b4mmvp69et1/7a4NkmSJD27pJOxd9FkycSq2pwkdLa9XFRVP9hlBWiPkxxQcG7bZUiSdiG3qejZIMlQVc0Yq9+u/tKfI5PcTmcf+KBBXJIkSc9lu3RlXNpWM2bMqPXr17ddhiRJ0jbZXVfGJUmSJDUM45IkSVJLDOOSJElSSwzjkiRJUksM45IkSVJLDOOSJElSSwzjkiRJUksM45IkSVJLDOOSJElSSwzjkiRJUksM45IkSVJLDOOSJElSSwzjkiRJUksM45IkSVJLDOOSJElSSwzjkiRJUksM45IkSVJLDOOSJElSSwzjkiRJUksM45IkSVJL+grjSRYkGUpya5LDt3eyJPs0Y6zb3jG2Ya4bu44XJ1ndHM9vni9O8q0ka5NcniQ7uyZJkiSp25hhPMmLgAuAY6tqXlXds72TVdVjVTUP+PH2jrENJncdTwQOSjKlOR7+eW9VzQb+H/A7u6AmSZIk6WmT+uhzMnBVVT0GkGRf4DrgxcADwFLg48BLgG82/S8ADgaOA34D+L/A4qp6ZOTgSQaA/wVMBR4Clowy3h09+i0Cfh84BChgAfA64J3A4UkGgQ81U90ELAQ2jJh/MjCNXfMHgiRJkvS0fsL4y4A1Xc+XAjdW1WeSvJ1OIJ4EXAR8ClgMnAF8G/hFVc1KcgLwDuADPcY/C7ilqpYlWbyV8X6zRz+Ah6rq3CTnA6+rqpXAyiQrqmoBQJIlwF3AKTwzjP8lcAVwZVX9qI97oV1saOhBkkvbLkOS1IKqS9ouQdrp+tkz/iBwaNfzVwK3Ncdr6Kx8A/wE+DfgEWCvpm14b/gg8KpRxj8SOL9Zxf4TYP9Rxhut313N4/3AfmNcy3fprIIPew9wIDCQ5PgxzpUkSZLGVT9hfCWwNMk+zfPvALOb4znAvVs5d2bzOAv451H63At8rKrmVtXMqvrgNvarrsfuN2EO9BhjOfDH3Q1V9STwr8ALtnIdkiRJ0rgbM4xX1U+BjwBrk6yhsxp+enN8NPBp4EngKWATsLn5gc6K81o6W04+mmROs7I9K8maJPsBVwHHJxlMcnPzJste4/Xq1z1X9zHA40luSzJ/+LWqur+r32bgz5t6pgNf2KY7J0mSJO2gVNXYvbZn4M4+7Z9V1YqdMoGeE5IDCs5tuwxJUgvcM649WZKhqpoxVr+d+aU/I1eqJUmSJHXZaSvj0niYMWNGrV+/vu0yJEmStsnusDIuSZIkaSsM45IkSVJLDOOSJElSSwzjkiRJUksM45IkSVJLDOPavT001HYFkiRJO41hXJIkSWqJYVySJElqiWFckiRJaolhXJIkSWqJYVySJElqiWFcu7f9j2q7AkmSpJ3GMC5JkiS1xDAuSZIktcQwLkmSJLXEMC5JkiS1xDAuSZIktcQwLkmSJLXEMC5JkiS1xDAuSZIktWTMMJ5kcZJvJVmb5PIk2dlFJdknya1J1m2trWlPkstG1Lu6OZ7fPN/l1yBJkiSNpZ+V8YnAe6tqNvD/gN/ZuSVBVT1WVfOAH2+trWmvqjpvRL0HJZnSHA//7NJrkCRJksYyqd+OSSYD04CfJrkGmAo8BCwBFgHvBT4OnAY8ANwM/D5wCFDAAmAAuA54cdNnKfBHwM+qamWSY4Ejq+rple4+aloFvKKqpnW9dBOwENgwyjU8I9BLkiRJbeg3jP8lcAVwJXA8cEtVLUuyGFhUVdclmQ08XlUzAZIsAR6qqnOTnA+8DnglcGNVfSbJ2+mEeOisXA8/TqRPVbURmJdkxYiX7gJO4Zlh/OlrqKof9TuH2jU09CDJpW2XIUlqSdUlbZcg7VT9voHzPcCBdFa2/zNwfpJB4E+A/bvG+vyI8+5qHu8H9qMTxm9r2tYAvzGi/6/0W3gfvktnFXzY09eQ5PhxnEeSJEnaLn1vU6mqJ5P8K7AMuL+qPtWj28aRp3U9BvgOMBv4LDAHuBd4hE5IBpgH/Gvf1W/d8qbWK3pcwwvGaQ5JkiRpu/WzMr4Z+PNmJXw68D+A45MMJrk5yZQkc4ATgC8lObjrvM0jjq8CTk+yBjga+DTw98D8JNfTCe2bk8xp5puVZE2S/UZpO7CrbTDJEcNzVdX9XfOOvIYvbOf9kiRJksZNqmrsXlJLkgMKzm27DElSS9wzrj1VkqGqmjFWP7/0R5IkSWpJ33vGpTYcddQBrF/vqogkSXp2cmVckiRJaolhXJIkSWqJYVySJElqiWFckiRJaolhXJIkSWqJn6ai3dtDQ/Ch9Nf3nX5mviRJ2rO4Mi5JkiS1xDAuSZIktcQwLkmSJLXEMC5JkiS1xDAuSZIktcRPU9Hubf+j4J3r265CkiRpp3BlXJIkSWqJYVySJElqidtUtFsbeuQRMjjY87WaO3eX1iJJkjTeXBmXJEmSWmIYlyRJklpiGJckSZJaYhiXJEmSWmIYlyRJkloy5qepJLkYOBl4FLgbuLCqalsmSTIb+J2quqzP/scCfw38qGk6q6ru35Y5t6G2G6tqYdfzBcB7gZ8D5wP3AV8CJlfVzHGaM8D/rKrzutomAH9L5w+kd1XVt3r1e645at99We+npkiSpGepflbGJwDnVNUc4N+B7QmkE4CJ29B/IvDxqprb/OyUIN6YPHyQ5EXABcCxVTWvqu6pqseqah7w4/GasDpGBuyXAfdV1fFV9a2t9JMkSdKzRN+fM55kEvAK4OdJbgCmAA8BbwNOBX4fOAQoYEEz9qeAXwO+CXwnyb7AdcCLgQeApcDHgZc0fU6mE4Z7zd/r3EV0VrE/DpzWtL8J+F/A1Ka+JU0tNwF7AY9X1fwkJwHvBA5PMgh8CNgPuKqqHuvjXnxyxD14ssccz+vRNhlYBbyiqqY1450G/BfgoCS/DXyk6TOy30CPa9viHlTVoq3VL0mSpN1Dv2H8ajqB+f3N9olvACcB04HTgc3AQ1V1bpLzgdcBrwRuqKrPJvmrZpylwI1V9Zkkb6cTJCcBF9EJ7ouBM4DVwH9qtow8BZzY69yquq7ZAvP48BaSJG8FbqmqZUkWN3OsBe6pqncNX1BVrQRWJllRVQuac98NrBnrZlTVkz3uwZqRcwD795h3IzAvyYqutpuSDNHZAnRh1/nP6AecNfLaet2DZ5OhoQdJLm27DEnSbqbqkrZLkMZFv2/gPIdOSP6tJKfSWZmdD1wM7Nv0uat5vJ/OCvMrgduatq82j91ta4DfaI5/Avwb8AidVWSAjzVbVOZV1RNbOXcC8PmuWo8Ezm9Wu/8E2L+q7gMuT3JWkhO3cp0PAodu5XUAet2DXnNsw7z92uLamvaR90CSJEl7gL4/TaWq1tHZpnI4sLqqNtEJ6E936XoM8I/A7KZtVvP4na62OcC921Dr1s7d2HV8L78M8jOr6oNN/Ruq6lrg+CSHdfUf6DpeCSxNss8YtUyjxz3oNcdW5t0ePa+tsXG0kyRJkrR76ieMb25+AP6Szorwe5LcQWc1fPOIPsPHfw0sTPJV4AVN21XA6UnWAEcDn6az1/opYNOIsYbHG7bFuUnmACcAX0pycFdfmG+IAAAgAElEQVS/45MMJrk5yZQkxyS5s9kKMhX4fte4jye5Lcn8qvopnf3aa5OsSXJEkjnNSvSspm0/YNnIe9BrjlHaDuwabzDJET3uM6P063Vtve6BJEmS9gDZxk8plHap5ICCc9suQ5K0m3HPuHZ3SYaqasZY/fzSH0mSJKklfX+0odSGo446gPXrXf2QJEnPTq6MS5IkSS0xjEuSJEktMYxLkiRJLTGMS5IkSS0xjEuSJEktMYxLkiRJLTGMS5IkSS0xjEuSJEktMYxLkiRJLTGMS5IkSS0xjEuSJEktMYxLkiRJLTGMS5IkSS0xjEuSJEktMYxLkiRJLTGMS5IkSS0xjEuSJEktMYxLkiRJLTGMS5IkSS0xjEuSJEktGTOMJ3lvknXN8VeSvLdHn32S3Drcb8RrN454niSX7UjR2zper/qSLE6yujme3zxfnORbSdYmuTxJxqtOSZIkaaR+VsYnAgPN8aTm+TNU1WNVNQ/4cY/zJ4/oW1V13rYWOpp+xhulvonAQUmmNMfDP++tqtnA/wN+Z7zqlCRJkkbqd5vKw0kOAH4OLE5yEkCSY5P0DMJJTkoyCMxKMtg8n9ysUG/o6rckyRVJbk6yOsleSfZNclNz3t80512dZEWS9yW5O8mcUcablOSGJLckWZbkhVu5rpuAhT1qnwxMo/cfF5IkSdK4mNRnv+8Cf9g8/g6/XB2fSI+VcoCqWgmsTLKiqhZ0vTQvyYoR3R+qqnOTnA+8DnglcGNVfSbJ24FFTa0XAZ8CFgNnVNVtI8erqieTfAM4CZgOnA5cM8p13QWcAmzoavtL4Argyqr60ah3RLvE0NCDJJe2XYYkaQ9RdUnbJUjbpN+V8e8AJzSP3X5lnOq4q3m8H9iPThi/rWlbA/xGc/wT4N+AR4C9eg2U5FRgKjAfuBjYd4y5v0tnFXzYe4ADgYEkx2/TVUiSJEnboN8w/s/Aa5vHn9EJqwDz+jh3YOwuVNdj6IT+2U3bHODePuuETrBeXVWbgDP66L8c+ONnFFP1JPCvwAu2YV5JkiRpm/QTxjfTCaafprMq/QVgfpLr6YTnzc3+7UE6+8PXJNmv6/zHk9zWfGLJgSP2kR/RjL+5a67NwFXA6UnWAEc3cz8JPAVsGu43ynjLgPckuYPOivto9W0GNlfV/V3zbgb+vOk7vblWSZIkaadIVY3dS2pJckDBuW2XIUnaQ7hnXLuLJENVNWOsfn7pjyRJktSSfj9NRWrFUUcdwPr1rnJIkqRnJ1fGJUmSpJYYxiVJkqSWGMYlSZKklhjGJUmSpJYYxiVJkqSWGMYlSZKklhjGJUmSpJYYxiVJkqSWGMYlSZKklhjGJUmSpJYYxiVJkqSWGMYlSZKklhjGJUmSpJYYxiVJkqSWGMYlSZKklhjGJUmSpJYYxiVJkqSWGMYlSZKklhjGJUmSpJaMGcaTnJnkniS3JLk5ySt3RWHN3DfuqrkkSZKkXa2flfFJwJ9V1WuBC4H37dySnmHyLpxLkiRJ2qW2dZvKy4AnklyT5NYky5NMTrIkyYYkFyVZl2Q5QJJLk9yeZE2SX00y0OPcxUn+uum3Ism+SU5KMgjMSjLYPN9ijqbvTU2fv+mq5YpmFX91kr3G+6ZJkiRJ42FSn/3+IskFwP3At4EfVNWyJIuBRVV1XZLZwONVNRMgyXzgeVU1a3iQJG8Fbuk+t3npF1U1K8kJwDuq6gPAyiQrqmpB1/kj57gIuLGqPpPk7V3jPVRV5yY5H3gdsHJ7bo4kSZK0M/Ubxv+sqlYAJPkEcGoTrAeALzZ9JgCf7zrnCOALI8Y5Enj1iHMfAtY1rw8Cb9pKHSPneCVwQ3O8BlgM/DNwV9N2P7Df2Jen3dXQ0IMkl7ZdhiRpD1R1SdslSGPqN4x3uxe4o6o+1eO1jV3HdwN/xC+Dds9zkywBZgLXA7PohOlhA2PM8R1gNvBZYE4z/kSgmtcLyJhXJEmSJLWgnz3jm5ufYVcBxzf7tG9OMiXJHOAE4EtJDgaoqr8DfpbkH5q+v9rr3GbMgSRrgYuAj3bN9XiS25LM7zVHM97pSdYARwOfHlHvyNolSZKk3UaqauxeO7OAzsr4z4a3wUjdkgMKzm27DEnSHshtKmpTkqGqmjFWv93hS39cvZYkSdJz0vbsGR9XVXV92zVIkiRJbWg9jEtbc9RRB7B+vf/NKEmSnp12h20qkiRJ0nOSYVySJElqiWFckiRJaolhXJIkSWqJYVySJElqiWFckiRJaolhXJIkSWqJYVySJElqiWFckiRJaolhXJIkSWqJYVySJElqiWFckiRJaolhXJIkSWqJYVySJElqiWFckiRJaolhXJIkSWqJYVySJElqiWFckiRJaolhXJIkSWrJmGE8yeQkNyYZTPLFpu0tSdYnuT3JS5O8t3l+V5I3d527IMlQkluTHJ5kn+Z43XhdQDouG9E2IcmqJDcnOWK0fpIkSVKbJvXR5wTgjqr6KECS3wZOBo4GqukzETgH+CdgRZJbgEeBC4Bjq+qxrvHmJVkxTvVTVQWcN6L5ZcB9VfWOMfpJkiRJrelnm8o3gd9KMtA8Pw14f1U9VY3hjlX1C+AjwBvoBParRgTxLSSZlOSGJLckWZbkhUmel2R1sxq/qunXq21ys9K+oWu804CbgFOavgtG6TeQ5JqmfXnTZ0mSDUkuSrIuyfJ+bqIkSZK0PcZcGa+q+5N8DPhEkquAA4DvJ3k/MA+4fMQpDwB/AOwDrOlj/CeTfAM4CZgOnN6cd09Vvaur6/4j26pqIyNW2qvqpiRDwIVVdWHX+SNX5M8CbqmqZUkWA4uq6roks4HHq2rmWLVr5xsaepDk0rbLkCTt4aouabsEqad+tqlQVd9K8lbgajph++Cq+tMkc4EjR3R/OfAw8C/AocDXtzZ2klOBqcB8OltiplXVfUkuT3IW8FBVfblXW/+X2dORwKub6xoAvti0TwA+v4NjS5IkSWPq5w2cvwJP77n+CfAV4N1JtgjySfaisy/7RmAlsDTJPmNMMQ1YXVWbgDOGG6tqQ1VdCxyf5LDR2nbAvcDHqmpuVc2sqg92vbZxB8eWJEmSxtTPnvGjkvxDkrXAQFWtoxO0vwp8kM6bNjfTWTVfA1xdVd+rqp/S2T++NsmaJEckmZNkEJjVtO0HLAPek+QO4C5gc5JjktzZbDeZSmdbTK+2A7vGGxz+5JSmns3DFzBKv6vohPrB5lNXpiSZQ2d1/ktJDt7emypJkiT1I13vv5R2O8kBBee2XYYkaQ/nnnHtakmGqmrGWP380h9JkiSpJX29gVNqy1FHHcD69a5mSJKkZydXxiVJkqSWGMYlSZKklhjGJUmSpJYYxiVJkqSWGMYlSZKklhjGJUmSpJYYxiVJkqSWGMYlSZKklhjGJUmSpJYYxiVJkqSWGMYlSZKklhjGJUmSpJYYxiVJkqSWGMYlSZKklhjGJUmSpJYYxiVJkqSWGMYlSZKklhjGJUmSpJYYxiVJkqSWGMYlSZKklowZxpOcmeSeJLckuTnJK3dkwnRctp3nPj/Jz5NM25EaxsMOXseCJENJbk1yeJJ9muN1O7O+JBOSrGp+j0eM1k+SJEm7xqQ++/xZVa1IMh14H7BoeyesqgLO287TjwNuAuYBG7a3hvGwvdeR5EXABcCxVfVY10vzkqzYyfW9DLivqt4xRj9JkiTtAtu6TeVlwBNJbmhWypcleWGS5yVZnWQwySqAUdomNyvATwfpJBckmdccvy7JeUkGklzT9F2eZHLT/Q+AvwBmNf33TfKFJGuTXJZk8ShtS5JsSHJRknXNmFvMsYuu42TgqhFBfAtJJo3zfT6Nzh8ypzR9F4zSr9d92eL+beO/G0mSJPXQz8o4wF8kuQC4H3gXcCZwEjAdOB1YA9xTVe/qOmf/kW1VtZEtV4A/D/xX4FbgNOBS4CzglqpalmQxnZX464ADq+q+JC9ozj0buKaqvpTkOmBir7aqui7JbODxqpoJkOStPeZYuwuuY0pzv7aqqp5M8o3xus9VdVOSIeDCqrqw6/yR17FFzb3u364yNPQgyaW7ckpJ0nNM1SVtl6DnsH7D+J9V1QqAJKcCU4H5wAnAtCYgX57kLOChqvpyr7ZeA1fVD5JMSTIAvLCq/iXJkcCrm8A8AHwxycHAq5J8Gjis2TJzGHBDM9TXm8debdD5X4DPdz3fYo5dcR3Ag8ChI2rbwnjf523Qq2bY8v5JkiRpB/UbxrtNA1ZX1aYkZwBfA6iqDcCGJB9Ncl9VfbtX2yhj/gPwX4C/b57fC9xRVZ8a7pBkKfDfquoLSU6hs3/8AeD3gC8Bx9BZOe7VNmxj1/EWc+yi63gRcFOS/z3GVpWdcZ/70fO+NDb2aJMkSdJ26mfP+ObmZ9gy4D1J7gDuAjYnOSbJnc02iKnA90dpOzDJIDCr2bd8RDPmZ4EL+eXK61XA8U2fm5NMAebS2UYCcDtwLHAFcH6SrwB7Az/v1ZZkDp3V5S81K+w959gV11FVPwU+AqxNsibJEUnmdI23Jsl+O+k+P+N3OUq/Xvel1/2TJEnSDkrnwzT2TEkmVtXmJAE+A1wEPDiyrap+0Gqh2m7JAQXntl2GJOlZzD3j2hmSDFXVjLH67elf+nNkktuBrwKDTeju1SZJkiTtdvbolXE9+82YMaPWr1/fdhmSJEnb5LmyMi5JkiTtsQzjkiRJUksM45IkSVJLDOOSJElSSwzjkiRJUksM45IkSVJLDOOSJElSSwzjkiRJUksM45IkSVJLDOOSJElSSwzjkiRJUksM45IkSVJLDOOSJElSSwzjkiRJUksM45IkSVJLDOOSJElSSwzjkiRJUksM45IkSVJLDOOSJElSSwzjkiRJUkvGDONJJie5Mclgki82bW9Jsj7J7UlemuS9zfO7kry569wFSYaS3Jrk8CT7NMfrxusC0nHZiLYJSVYluTnJEaP1kyRJkto0qY8+JwB3VNVHAZL8NnAycDRQTZ+JwDnAPwErktwCPApcABxbVY91jTcvyYpxqp+qKuC8Ec0vA+6rqneM0U+SJElqTT/bVL4J/FaSgeb5acD7q+qpagx3rKpfAB8B3kAnsF81IohvIcmkJDckuSXJsiQvTPK8JKub1fhVTb9ebZOblfYNXeOdBtwEnNL0XTBKv4Ek1zTty5s+S5JsSHJRknVJlvdzEyVJkqTtMebKeFXdn+RjwCeSXAUcAHw/yfuBecDlI055APgDYB9gTR/jP5nkG8BJwHTg9Oa8e6rqXV1d9x/ZVlUbGbHSXlU3JRkCLqyqC7vOH7kifxZwS1UtS7IYWFRV1yWZDTxeVTPHql0739DQgySXtl2GJOk5ouqStkvQc0w/21Soqm8leStwNZ2wfXBV/WmSucCRI7q/HHgY+BfgUODrWxs7yanAVGA+nS0x06rqviSXJzkLeKiqvtyrrf/L7OlI4NXNdQ0AX2zaJwCf38GxJUmSpDH18wbOX4Gn91z/BPgK8O4kWwT5JHvR2Zd9I7ASWJpknzGmmAasrqpNwBnDjVW1oaquBY5PcthobTvgXuBjVTW3qmZW1Qe7Xtu4g2NLkiRJY+pnz/hRSf4hyVpgoKrW0QnaXwU+SOdNm5vprJqvAa6uqu9V1U/p7B9fm2RNkiOSzEkyCMxq2vYDlgHvSXIHcBewOckxSe5stptMpbMtplfbgV3jDQ5/ckpTz+bhCxil31V0Qv1g86krU5LMobM6/6UkB2/vTZUkSZL6ka73X0q7neSAgnPbLkOS9BzhnnGNlyRDVTVjrH5+6Y8kSZLUkr7ewCm15aijDmD9elcpJEnSs5Mr45IkSVJLDOOSJElSSwzjkiRJUksM45IkSVJLDOOSJElSSwzjkiRJUksM45IkSVJLDOOSJElSSwzjkiRJUksM45IkSVJLDOOSJElSSwzjkiRJUksM45IkSVJLDOOSJElSSwzjkiRJUksM45IkSVJLDOOSJElSSwzjkiRJUksM45IkSVJLDOOSJElSS8YM40kuTrI+yW1JPppfumyU/rOTnLctRSRZkGQoya1JDk+yT3O8blvGGWOOLWpOMiHJqiQ3JzlitH6SJEnSztDPyvgE4JyqmgP8OzCzOkYL3BOAif0WkORFwAXAsVU1r6ruqarHqmoe8ON+xxnLKDW/DLivqo6vqm9tpZ8kSZI07vreppJkEvAK4JFm1XpD12vPT7KiWcle2LTtm+QLSdYmuSzJ4iQDSa5pzl+eZDJwMnBVVT021vxJbkhyS5JlSV6Y5HlJVicZTLKq6derbXKPmk8DbgJOafouGKXfFjUnWZJkQ5KLkqxLsrzf+yhJkiQNm9Rnv6uBlwDvr6r/D5iXZEXX628Fbqiqzyb5q6btbOCaqvpSkuvorJafBdxSVcuSLAYWAVOANWMVUFVPJvkGcBIwHTi9Oe+eqnpXV9f9R7ZV1caRNVfVTUmGgAur6sKu80de2xY1V9V1SWYDj1fVzLFq1/YbGnqQ5NK2y5AkPQdVXdJ2CXoO6Hdl/BzgDOC3Rnn9lcBtzfFXm8fDgK83x8OPRwLnJxkE/oROcH4QOHSsApKcCkwF5gMXA/tW1X3A5UnOSnIiQK+2HdSrZujcu8+Pw/iSJEl6jup7m0pVrQNekeTlPV7+R2B2czyreXwA+L3m+Jjm8V7gY1U1t6pmVtUHgZXA0iT7jFHCNGB1VW2i84fBcF0bqupa4Pgkh43WtgN61Txs4w6OLUmSpOewfsL45uYH4C+B9zWrxLOavdZHAH8NLEzyVeAFTf8r6KwofwXYG/g5cBWdgDzYfILJlKr6KfARYG2SNUmOSDKna441SfYDlgHvSXIHcBewOckxSe5stpv8/+3df6zddX3H8ecLWnAQROoWoUQQmGMYiIw2btoCtZsrmIjgWDbmMBinLBp+BJkxoBI2xbDpApPpsLKRbJRoIhJEpFlaLrCCsnslEZSwpCJZbGxEfgQEOuje++N8C/fe/jjntveez7nd85HcnO/5nM/3c97nfnJOX/fTzznnKODxnbQdvoOapz82dtJvu5qTnAqcBtye5IiZ/colSZKknlTV3Ayc7FtVW5ME+AZwSVX995zcmfZayeKC81uXIUn6f8g949oTSSaqamm/fnP5pT8nJvkPenvIxwzikiRJ0lRztjIuzYalS5fW+Ph46zIkSZJmZBRWxiVJkiTtgmFckiRJasQwLkmSJDViGJckSZIaMYxLkiRJjSxoXYC0S5sn4ItpXYUkSdpbfHy0PknQlXFJkiSpEcO4JEmS1IhhXJIkSWrEMC5JkiQ1YhiXJEmSGvHTVDTa3rAEPj7eugpJkqQ54cq4JEmS1IhhXJIkSWrEbSoaaRPPPkvGxlqXIUmS9hK1YkXrEqZwZVySJElqxDAuSZIkNWIYlyRJkhoxjEuSJEmNGMYlSZKkRnb5aSpJzgbeVFVfSPIB4NeAl4CPAi8C7wNWAZ8AngJ+BHy0qirJmcCngWeAC4GfALcD+1fVstkoPkmAf6iqCya17QN8h94fGpdW1UM76qf5YclBBzE+Yu96liRJmi39Vsa/CZyW5PXAB4DvAWcAbwNOBn4B7At8uqpOAZ4D3prkEOAi4OSqWllVD1fV81W1sjtnVlTP9IB9GPCTqlpVVQ/top8kSZLU1C7DeFUVcA2wHrgReC9wVVX9bxdwa1vfJPsDx9AL22cAq6vq+V2Nn2RBkpuSrEuyJsnBSQ5McmeSsSTf7frtqG3/JOuTbJw03h/R+wPivV3fM3fSb2GSG7r2m7s+5yXZmOSSJBuS3DyTX6QkSZI0U4N86c89wJuBfweuBB5PchWwEvhK1+dzwPXAV6vqZ0kOA+7qN3BVvZzkAeA9wHHA2d15D1fVpZO6vmF6W1VtAVYmuXVS2zeTTAAXV9XFk86f0g/4ILCuqtYkORc4p6puTHIK8MJsbaPRnpuY2ERyZesyJEmaouqK1iVoLzHIGzg/AXyhu9wEHFFVlwGfBA7p+lwOHA4sTLKq63d0v4GTnAUcBZwOfAY4qKp+AnwlyQeTvBtgR2176ETgwiRjwF/SC/vQ+33cMgvjS5IkSX3tMownORT4nar6DHAksA74ZJLtVtSr6mXg58BrgW8DH05yQJ/7Pwa4s6peAt4/aayNVfUvwKokv72ztj3wCHBdVa2oqmVVdfWk27bs4diSJEnSQPqtjF9Ob2sKwOeBP6UXtO8FrgZ+DGwF/qZbZT4O+FZVPUVvr/k9Se5KckKSU7s+y7u2RcAa4PIk9wEPAluT/F6SH3TbTY6ity1mR22HTxpvLMkJXZ1bux8AdtJvNb1QP5ZkbZJDk5wKnAbcnuSI3fptSpIkSTOQSe/BlEZOsrjg/NZlSJI0hXvG1U+Siapa2q+fX/ojSZIkNTLIp6lIzSxZspjxcVcfJEnS3smVcUmSJKkRw7gkSZLUiGFckiRJasQwLkmSJDViGJckSZIaMYxLkiRJjRjGJUmSpEYM45IkSVIjhnFJkiSpEcO4JEmS1IhhXJIkSWrEMC5JkiQ1YhiXJEmSGjGMS5IkSY0YxjXSJp59tnUJkiRJc8YwLkmSJDViGJckSZIaMYxLkiRJjRjGJUmSpEb6hvEk39hBW5J8aW5KgiT7J/l6krEkt3Vt1yQ5tjs+Psnfd8dnJplIsj7J8XNVkyRJkjTbFgzQZ7/pDVVVwAWzX84rTgPuq6prJ7XdC5wCPAq8ExhLcghwEXByVT0/h/WokSUHHdS6BEmSpDkz420q3ar1+iQbJ7Wdl+T6JGuT3JnkNUkWJrmh63tzd96CJDclWZdkTZKDu3M3JrkkyYYkNwM/BN6SZOGku74bWN4dL++unwGsNohLkiRpPppxGK+qLVW1Enho2k2bq2oVcAfwLuCDwLqu7x3AOVX1MvAAUMBxwNlVdSO9YP1CVS2rqnOq6jHgOuDLSd7W3e8TwCFJAhxYVc8AhwEbkSRJkuahQbapDOrB7vIxYBFwInBSko8AC4HbkpwFHAWcTm8ryjHdOfsAt0werKoe6s79WpLNVfU48FNgFfBw120TcDTw/Vl8HBohExObSK5sXYYkSVNUXdG6BO0lZvPTVGrSZYBHgOuqakW34n01vfB9Z1W9BLx/2vlbth0k2Q9e2Zv+JLC4u+lu4DJgXXf928CHkxwwi49DkiRJGopBwvg7uk81GUvyoSSHJxkDlndtJwBbux8mHa8GVnV91iY5FFgDXJ7kPnor6VuTnEpvlfz2JEd0YyxJcn+Se4CFVXV/1343sBTYAFBVTwHXAPckuaurRZIkSZoX0lt8lkZTsrjg/NZlSJI0hdtU1E+Siapa2q+fX/ojSZIkNWIYlyRJkhqZzU9TkWbdkiWLGR/3vwIlSdLeyZVxSZIkqRHDuCRJktSIYVySJElqxDAuSZIkNWIYlyRJkhoxjEuSJEmNGMYlSZKkRgzjkiRJUiOGcUmSJKkRw7gkSZLUiGFckiRJasQwLkmSJDViGJckSZIaMYxLkiRJjRjGJUmSpEYM45IkSVIjhnFJkiSpEcO4JEmS1IhhXJIkSWqkbxhP8o0dtCXJl+amJEiyf5KvJxlLclvXdk2SY7vj45P8fXd8ZpKJJOuTHD9XNUmSJEmzbcEAffab3lBVBVww++W84jTgvqq6dlLbvcApwKPAO4GxJIcAFwEnV9Xzc1iPJEmSNOtmvE2lW7Ven2TjpLbzklyfZG2SO5O8JsnCJDd0fW/uzluQ5KYk65KsSXJwd+7GJJck2ZDkZuCHwFuSLJx013cDy7vj5d31M4DVBnFJkiTNR4OsjE9RVVuAlUlunXbT5qo6P8mFwLuAw4B1VbUmybnAOVV1Y5IHgPcAxwFnV9UNSU4BXqiqZdsGS3Id8OUkq6vqgap6IskhSQIcWFXPJDkMuGu3HrnmhYmJTSRXti5DkqQpqq5oXYL2EjMO47vwYHf5GLAIOBE4KclHgIXAbUnOAo4CTqe3FeWY7px9gFsmD1ZVD3Xnfi3J5qp6HPgpsAp4uOu2CTga+P4sPg5JkiRpKGbz01Rq0mWAR4DrqmpFVS2rqqvphe87q+ol4P3Tzt+y7SDJfvDK3vQngcXdTXcDlwHruuvfBj6c5IBZfBySJEnSUAwSxt/RfarJWJIPJTk8yRiwvGs7Adja/TDpeDWwquuzNsmhwBrg8iT30VtJ35rkVHqr5LcnOaIbY0mS+5PcAyysqvu79ruBpcAGgKp6CrgGuCfJXV0tkiRJ0ryQ3uKzNJqSxQXnty5DkqQp3DOufpJMVNXSfv380h9JkiSpkdl8A6c065YsWcz4uKsPkiRp7+TKuCRJktSIYVySJElqxDAuSZIkNWIYlyRJkhoxjEuSJEmNGMYlSZKkRgzjkiRJUiOGcUmSJKkRw7gkSZLUiGFckiRJasQwLkmSJDViGJckSZIaMYxLkiRJjRjGJUmSpEYM4xppE88+27oESZKkOWMYlyRJkhoxjEuSJEmNGMYlSZKkRgzjkiRJUiOGcUmSJKmRvmE8yZ8neTjJuiRrk7w5PV+a6Z0lOSDJ+iQbprXv1nja+y056KDWJUiSJM2ZQVbGFwCfqqrfBy4G/rp6LpjpnVXV81W1EvjFtPbdGk+SJEmazxbMsP9hwItJ1gNHVtUxAEnOBd4J/BbwBHAu8CLwT8BRwGbgvKraMn3AJPsD35023nnA24E3AQWcCWwdZDxJkiRpvhg0jH82yUXAY8ClVfXLJLdOun1f4H+qanmS04CPAU8C66pqTRfWzwFunD5wF6hXThsPYHNVnZ/kQuBd9P4Q6Due9i4TE5tIrmxdhiRJ26m6onUJ2gsMGsY/VVXTw/J02/aBjwEfAJ4GTkryEWAhcNsMa3uwu3wMWAScuIfjSZIkSSNlpttUdmUZ8K/AcuC/gF8C91XVv+3meDXpMsAjezieJEmSNFIGeQPn1u4HgCSHJxkDlicZS3JCd9PCJPcAlwDXAquBVV2fteILLTEAAARsSURBVEkOTXLqpHPvSrJoJ+NNvs9tx9uNt8ePXpIkSWooVdW/V79Bem+4fHqArSzSjCSLC85vXYYkSdtxz7h2JclEVS3t12+2vvRnyuq5JEmSpP5mZWVcmitLly6t8fHx1mVIkiTNyLBXxiVJkiTNkGFckiRJasQwLkmSJDViGJckSZIaMYxLkiRJjRjGJUmSpEYM45IkSVIjhnFJkiSpEcO4JEmS1IhhXJIkSWrEMC5JkiQ1YhiXJEmSGjGMS5IkSY0YxiVJkqRGDOOSJElSI4ZxSZIkqRHDuCRJktSIYVySJElqxDAuSZIkNWIYlyRJkhoxjEuSJEmNGMYlSZKkRgzjkiRJUiOpqtY1SDuV5Fng0dZ1aCC/DjzRuggNxLmaP5yr+cO5mj+GNVdHVtVv9Ou0YAiFSHvi0apa2roI9Zdk3LmaH5yr+cO5mj+cq/lj1ObKbSqSJElSI4ZxSZIkqRHDuEbdV1sXoIE5V/OHczV/OFfzh3M1f4zUXPkGTkmSJKkRV8YlSZKkRgzjkiRJUiOGcY2EJH+b5PtJvrwnfTT3+s1DkjcmuSPJWJJ/TpJh16ieQZ8zST6b5JvDqkvbG/A18Iwk93XPrWOHWZ9eNcBr4BuSrO3m6dYkrx12jepJ8uYkjyQ5fhd9mmcLw7iaS3ICsG9V/S7w8yTLdqeP5t6A8/AU8MdVtQLYBDhXDQz6nEnyFmALsO8w69OrBnwNPBx4H3BKVa2oKr8MrYEBn1d/AVzVvQbeApw1xBLVSbIvcDHwHXbyvTqjki0M4xoFy4E7ktwEfLe7vjt9NPf6zkNVPVdVv+quPgc8M8T69KpBnzOXAl8YWlXakUHm6s+AnwF3J/ncMIvTFIPM1b3AyiQHAiuADcMrT9tU1daq+hi9f4d2ZiSyhWFco2ARvcC2D/A08Prd7KO5N/A8JHkd8MaqemhItWmqvnOV5E+A26rqhSHXpqkGeV4dBby2qpYBLyf5wyHWp1cNMlf3AwcAlwOPABuHVp1maiSyhWFco+Bp4OCqOgd4XXd9d/po7g00D0n2A64CPjPE2jTVIHP1duDMJDcCJyX5uyHWp1cNMlfPAdv29d8GvHVItWmqQebqKuAfq+oyYB3wiSHWp5kZiWxhGNco+E/g3d3x6d313emjudd3HpIsBK4FvlhVvxxibZqq71xV1cVVdV5VnQf8oKr+aoj16VWDvL59Dzi5Oz4Z+PEQ6tL2BpmrI4AXu+NfAb85hLq0e0YiWxjG1VxVPQDsl+Re4Eh6Kwkz7qO5N+A8XA78AXBD92kCZw+zRvXsxnNmy9xXpR0ZcK6+BRzd9TkWuGOIJaoz4Fx9Fri++x+nq4HPD69C7cDW7mc7o5It/AZOjaQk+wM/Ao6rqpda16Odc67mD+dq/nCu5g/nav4Y1bkyjGtkJVlUVU+2rkP9OVfzh3M1fzhX84dzNX+M4lwZxiVJkqRG3DMuSZIkNWIYlyRJkhoxjEuSJEmNGMYlSZKkRgzjkiRJUiP/B24QcJkWF3fWAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "indices = np.arange(len(results))\n",
    "\n",
    "results = [[x[i] for x in results] for i in range(4)]\n",
    "\n",
    "clf_names, score, training_time, test_time = results\n",
    "training_time = np.array(training_time) / np.max(training_time)\n",
    "test_time = np.array(test_time) / np.max(test_time)\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.title(\"Score\")\n",
    "plt.barh(indices, score, .2, label=\"score\", color='navy')\n",
    "plt.barh(indices + .3, training_time, .2, label=\"training time\",\n",
    "         color='c')\n",
    "plt.barh(indices + .6, test_time, .2, label=\"test time\", color='darkorange')\n",
    "plt.yticks(())\n",
    "plt.legend(loc='best')\n",
    "plt.subplots_adjust(left=.25)\n",
    "plt.subplots_adjust(top=.95)\n",
    "plt.subplots_adjust(bottom=.05)\n",
    "\n",
    "for i, c in zip(indices, clf_names):\n",
    "    plt.text(-.3, i, c)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7952231301068511, 0.7940917661847895, 0.7937146448774356, 0.7929604022627278, 0.7802639849151477, 0.7751099937146448, 0.7693274670018856, 0.7565053425518542, 0.7504714016341923, 0.7449402891263356, 0.7338780641106223, 0.722438717787555, 0.7211816467630421, 0.7174104336895034, 0.7029541169076052, 0.6248900062853551]\n"
     ]
    }
   ],
   "source": [
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7484600879949717\n"
     ]
    }
   ],
   "source": [
    "print(np.average(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7952231301068511\n"
     ]
    }
   ],
   "source": [
    "print(max(score))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
