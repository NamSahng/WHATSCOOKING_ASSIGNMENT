{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results of\n",
    "\n",
    "\n",
    "MODEL_1 and 3 <br>\n",
    "CLASSIFIED WITH WORDS and PHRASE<br>\n",
    "ngram = 1 \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import logging\n",
    "import numpy as np\n",
    "from optparse import OptionParser\n",
    "import sys\n",
    "from time import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB, ComplementNB, MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neighbors import NearestCentroid\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.utils.extmath import density\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "import re\n",
    "import itertools\n",
    "import os.path\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_numbers(ing):\n",
    "    # remove numbers from ingredients\n",
    "    \n",
    "    return [[re.sub(\"\\d+\", \"\", x) for x in y] for y in ing]\n",
    "\n",
    "    \n",
    "def remove_special_chars(ing):\n",
    "    # remove certain special characters from ingredients\n",
    "   \n",
    "    ing = [[x.replace(\"-\", \" \") for x in y] for y in ing] \n",
    "    ing = [[x.replace(\"&\", \" \") for x in y] for y in ing] \n",
    "    ing = [[x.replace(\"'\", \" \") for x in y] for y in ing] \n",
    "    ing = [[x.replace(\"''\", \" \") for x in y] for y in ing] \n",
    "    ing = [[x.replace(\"%\", \" \") for x in y] for y in ing] \n",
    "    ing = [[x.replace(\"!\", \" \") for x in y] for y in ing] \n",
    "    ing = [[x.replace(\"(\", \" \") for x in y] for y in ing] \n",
    "    ing = [[x.replace(\")\", \" \") for x in y] for y in ing] \n",
    "    ing = [[x.replace(\"/\", \" \") for x in y] for y in ing] \n",
    "    ing = [[x.replace(\"/\", \" \") for x in y] for y in ing] \n",
    "    ing = [[x.replace(\",\", \" \") for x in y] for y in ing] \n",
    "    ing = [[x.replace(\".\", \" \") for x in y] for y in ing] \n",
    "    ing = [[x.replace(u\"\\u2122\", \" \") for x in y] for y in ing] \n",
    "    ing = [[x.replace(u\"\\u00AE\", \" \") for x in y] for y in ing] \n",
    "    ing = [[x.replace(u\"\\u2019\", \" \") for x in y] for y in ing] \n",
    "\n",
    "    return ing\n",
    "    \n",
    "    \n",
    "def make_lowercase(ing):\n",
    "    # make all letters lowercase for all ingredients\n",
    "    \n",
    "    return [[x.lower() for x in y] for y in ing]\n",
    "    \n",
    "    \n",
    "def remove_extra_whitespace(ing):\n",
    "    # removes extra whitespaces\n",
    "    \n",
    "    return [[re.sub( '\\s+', ' ', x).strip() for x in y] for y in ing] \n",
    "    \n",
    "    \n",
    "def stem_words(ing):\n",
    "    # word stemming for ingredients\n",
    "    \n",
    "    lmtzr = WordNetLemmatizer()\n",
    "    \n",
    "    def word_by_word(strng):\n",
    "        \n",
    "        return \" \".join([\"\".join(lmtzr.lemmatize(w)) for w in strng.split()])\n",
    "    \n",
    "    return [[word_by_word(x) for x in y] for y in ing] \n",
    "    \n",
    "    \n",
    "def remove_units(ing):\n",
    "    # remove certain words from ingredients\n",
    "    \n",
    "    remove_list = ['g', 'lb', 's', 'n']\n",
    "        \n",
    "    def check_word(strng):\n",
    "        \n",
    "        s = strng.split()\n",
    "        resw  = [word for word in s if word.lower() not in remove_list]\n",
    "        \n",
    "        return ' '.join(resw)\n",
    "\n",
    "    return [[check_word(x) for x in y] for y in ing] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### by all the words\n",
    "\n",
    "df=pd.read_json('./train.json')\n",
    "X = df['ingredients'].values\n",
    "Y = df['cuisine'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = make_lowercase(X)\n",
    "X = remove_numbers(X)\n",
    "X = remove_special_chars(X)\n",
    "X = remove_extra_whitespace(X)\n",
    "X = remove_units(X)\n",
    "X = stem_words(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ingredients_preprocessed'] = X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ingredients_as_sentence'] = df['ingredients_preprocessed'].apply(', '.join)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6677\n"
     ]
    }
   ],
   "source": [
    "uniques = list(set([item for sublist in X for item in sublist]))\n",
    "print(len(uniques))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['ingredients_as_sentence'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8285\n"
     ]
    }
   ],
   "source": [
    "for ing in uniques:\n",
    "    temp = ing.split(' ')\n",
    "    for word in temp:\n",
    "        if word not in uniques:\n",
    "            uniques.append(word)\n",
    "print(len(uniques))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngram = 1     #### CUSTOMIZE \n",
    "\n",
    "# from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1, ngram), vocabulary=uniques)\n",
    "X = vectorizer.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 7434)\t0.4043455766076157\n",
      "  (0, 7412)\t0.3167276767158082\n",
      "  (0, 7058)\t0.24911439037394897\n",
      "  (0, 6765)\t0.35697121618985855\n",
      "  (0, 6533)\t0.14805335445131518\n",
      "  (0, 5445)\t0.10970675831861157\n",
      "  (0, 4551)\t0.2774555999091271\n",
      "  (0, 4306)\t0.15176502988889437\n",
      "  (0, 3811)\t0.2396832355219728\n",
      "  (0, 3570)\t0.1118145095283498\n",
      "  (0, 3272)\t0.10391647275486823\n",
      "  (0, 3094)\t0.3560443893695225\n",
      "  (0, 2952)\t0.1457359419289999\n",
      "  (0, 2283)\t0.34827614404150986\n",
      "  (0, 1263)\t0.20790510180038077\n",
      "  (0, 122)\t0.13948352921322324\n"
     ]
    }
   ],
   "source": [
    "print(X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31819, 8285) (7955, 8285) (31819,) (7955,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2 ,random_state=2019, stratify = Y )\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark(clf):\n",
    "    print('_' * 80)\n",
    "    print(\"Training: \")\n",
    "    print(clf)\n",
    "    t0 = time()\n",
    "    clf.fit(X_train, y_train)\n",
    "    train_time = time() - t0\n",
    "    print(\"train time: %0.3fs\" % train_time)\n",
    "\n",
    "    t0 = time()\n",
    "    pred = clf.predict(X_test)\n",
    "    test_time = time() - t0\n",
    "    print(\"test time:  %0.3fs\" % test_time)\n",
    "\n",
    "    score = metrics.accuracy_score(y_test, pred)\n",
    "    print(\"accuracy:   %0.3f\" % score)\n",
    "    \n",
    "    \n",
    "    if hasattr(clf, 'coef_'):\n",
    "        print(\"dimensionality: %d\" % clf.coef_.shape[1])\n",
    "        print(\"density: %f\" % density(clf.coef_))\n",
    "        \n",
    "    print(\"classification report:\")\n",
    "    print(metrics.classification_report(y_test, pred,target_names=target_names))\n",
    "    \n",
    "    \n",
    "    #if opts.print_cm:\n",
    "    #print(\"confusion matrix:\")\n",
    "    #print(metrics.confusion_matrix(y_test, pred))\n",
    "\n",
    "    print()\n",
    "    clf_descr = str(clf).split('(')[0]\n",
    "    return clf_descr, score, train_time, test_time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Ridge Classifier\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,\n",
      "        max_iter=None, normalize=False, random_state=2019, solver='sag',\n",
      "        tol=0.01)\n",
      "train time: 2.699s\n",
      "test time:  0.003s\n",
      "accuracy:   0.764\n",
      "dimensionality: 8285\n",
      "density: 0.322028\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   brazilian       0.75      0.43      0.55        93\n",
      "     british       0.74      0.30      0.43       161\n",
      "cajun_creole       0.79      0.65      0.72       309\n",
      "     chinese       0.72      0.88      0.80       535\n",
      "    filipino       0.73      0.43      0.54       151\n",
      "      french       0.61      0.66      0.63       529\n",
      "       greek       0.82      0.68      0.74       235\n",
      "      indian       0.83      0.89      0.86       601\n",
      "       irish       0.69      0.29      0.40       133\n",
      "     italian       0.76      0.91      0.83      1568\n",
      "    jamaican       0.73      0.54      0.62       105\n",
      "    japanese       0.87      0.67      0.76       284\n",
      "      korean       0.85      0.61      0.71       166\n",
      "     mexican       0.88      0.92      0.90      1288\n",
      "    moroccan       0.83      0.67      0.74       164\n",
      "     russian       0.75      0.34      0.46        98\n",
      " southern_us       0.66      0.80      0.72       864\n",
      "     spanish       0.75      0.36      0.49       198\n",
      "        thai       0.72      0.77      0.75       308\n",
      "  vietnamese       0.73      0.44      0.55       165\n",
      "\n",
      "   micro avg       0.76      0.76      0.76      7955\n",
      "   macro avg       0.76      0.61      0.66      7955\n",
      "weighted avg       0.77      0.76      0.75      7955\n",
      "\n",
      "\n",
      "================================================================================\n",
      "Perceptron\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "Perceptron(alpha=0.0001, class_weight=None, early_stopping=False, eta0=1.0,\n",
      "      fit_intercept=True, max_iter=50, n_iter=None, n_iter_no_change=5,\n",
      "      n_jobs=None, penalty=None, random_state=2019, shuffle=True,\n",
      "      tol=0.001, validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "train time: 0.355s\n",
      "test time:  0.003s\n",
      "accuracy:   0.733\n",
      "dimensionality: 8285\n",
      "density: 0.141002\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   brazilian       0.48      0.61      0.54        93\n",
      "     british       0.40      0.34      0.37       161\n",
      "cajun_creole       0.57      0.67      0.62       309\n",
      "     chinese       0.72      0.85      0.78       535\n",
      "    filipino       0.61      0.50      0.55       151\n",
      "      french       0.54      0.61      0.57       529\n",
      "       greek       0.73      0.69      0.70       235\n",
      "      indian       0.82      0.89      0.85       601\n",
      "       irish       0.62      0.37      0.46       133\n",
      "     italian       0.84      0.78      0.81      1568\n",
      "    jamaican       0.59      0.68      0.63       105\n",
      "    japanese       0.80      0.64      0.71       284\n",
      "      korean       0.62      0.80      0.69       166\n",
      "     mexican       0.88      0.90      0.89      1288\n",
      "    moroccan       0.76      0.69      0.72       164\n",
      "     russian       0.45      0.35      0.39        98\n",
      " southern_us       0.65      0.73      0.69       864\n",
      "     spanish       0.64      0.44      0.52       198\n",
      "        thai       0.82      0.66      0.73       308\n",
      "  vietnamese       0.71      0.50      0.58       165\n",
      "\n",
      "   micro avg       0.73      0.73      0.73      7955\n",
      "   macro avg       0.66      0.63      0.64      7955\n",
      "weighted avg       0.74      0.73      0.73      7955\n",
      "\n",
      "\n",
      "================================================================================\n",
      "Passive-Aggressive\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "PassiveAggressiveClassifier(C=1.0, average=False, class_weight=None,\n",
      "              early_stopping=False, fit_intercept=True, loss='hinge',\n",
      "              max_iter=50, n_iter=None, n_iter_no_change=5, n_jobs=None,\n",
      "              random_state=2019, shuffle=True, tol=0.001,\n",
      "              validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "train time: 0.770s\n",
      "test time:  0.003s\n",
      "accuracy:   0.765\n",
      "dimensionality: 8285\n",
      "density: 0.206500\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   brazilian       0.70      0.61      0.66        93\n",
      "     british       0.59      0.42      0.49       161\n",
      "cajun_creole       0.72      0.67      0.69       309\n",
      "     chinese       0.79      0.79      0.79       535\n",
      "    filipino       0.63      0.66      0.64       151\n",
      "      french       0.56      0.66      0.61       529\n",
      "       greek       0.76      0.74      0.75       235\n",
      "      indian       0.88      0.85      0.87       601\n",
      "       irish       0.53      0.38      0.44       133\n",
      "     italian       0.84      0.84      0.84      1568\n",
      "    jamaican       0.81      0.69      0.74       105\n",
      "    japanese       0.77      0.71      0.74       284\n",
      "      korean       0.75      0.82      0.78       166\n",
      "     mexican       0.89      0.91      0.90      1288\n",
      "    moroccan       0.74      0.73      0.74       164\n",
      "     russian       0.49      0.44      0.46        98\n",
      " southern_us       0.68      0.78      0.73       864\n",
      "     spanish       0.61      0.48      0.54       198\n",
      "        thai       0.77      0.75      0.76       308\n",
      "  vietnamese       0.65      0.54      0.59       165\n",
      "\n",
      "   micro avg       0.77      0.77      0.77      7955\n",
      "   macro avg       0.71      0.67      0.69      7955\n",
      "weighted avg       0.77      0.77      0.76      7955\n",
      "\n",
      "\n",
      "================================================================================\n",
      "kNN\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=None, n_neighbors=10, p=2,\n",
      "           weights='uniform')\n",
      "train time: 0.044s\n",
      "test time:  10.028s\n",
      "accuracy:   0.753\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   brazilian       0.60      0.54      0.56        93\n",
      "     british       0.63      0.43      0.51       161\n",
      "cajun_creole       0.69      0.67      0.68       309\n",
      "     chinese       0.72      0.87      0.78       535\n",
      "    filipino       0.67      0.58      0.62       151\n",
      "      french       0.56      0.61      0.59       529\n",
      "       greek       0.73      0.65      0.68       235\n",
      "      indian       0.87      0.88      0.87       601\n",
      "       irish       0.67      0.51      0.58       133\n",
      "     italian       0.75      0.88      0.81      1568\n",
      "    jamaican       0.83      0.57      0.68       105\n",
      "    japanese       0.87      0.65      0.75       284\n",
      "      korean       0.78      0.72      0.75       166\n",
      "     mexican       0.84      0.88      0.86      1288\n",
      "    moroccan       0.86      0.76      0.80       164\n",
      "     russian       0.71      0.30      0.42        98\n",
      " southern_us       0.72      0.74      0.73       864\n",
      "     spanish       0.68      0.35      0.46       198\n",
      "        thai       0.78      0.74      0.76       308\n",
      "  vietnamese       0.86      0.47      0.61       165\n",
      "\n",
      "   micro avg       0.75      0.75      0.75      7955\n",
      "   macro avg       0.74      0.64      0.68      7955\n",
      "weighted avg       0.75      0.75      0.75      7955\n",
      "\n",
      "\n",
      "================================================================================\n",
      "Random forest\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=None,\n",
      "            oob_score=False, random_state=2019, verbose=0,\n",
      "            warm_start=False)\n",
      "train time: 44.484s\n",
      "test time:  0.312s\n",
      "accuracy:   0.754\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   brazilian       0.88      0.39      0.54        93\n",
      "     british       0.82      0.25      0.38       161\n",
      "cajun_creole       0.78      0.64      0.71       309\n",
      "     chinese       0.73      0.89      0.80       535\n",
      "    filipino       0.80      0.46      0.58       151\n",
      "      french       0.60      0.53      0.56       529\n",
      "       greek       0.89      0.55      0.68       235\n",
      "      indian       0.82      0.92      0.87       601\n",
      "       irish       0.80      0.43      0.56       133\n",
      "     italian       0.70      0.93      0.80      1568\n",
      "    jamaican       0.96      0.48      0.64       105\n",
      "    japanese       0.87      0.64      0.74       284\n",
      "      korean       0.91      0.63      0.74       166\n",
      "     mexican       0.85      0.94      0.89      1288\n",
      "    moroccan       0.91      0.64      0.75       164\n",
      "     russian       0.77      0.23      0.36        98\n",
      " southern_us       0.65      0.77      0.70       864\n",
      "     spanish       0.85      0.31      0.45       198\n",
      "        thai       0.79      0.78      0.79       308\n",
      "  vietnamese       0.83      0.42      0.56       165\n",
      "\n",
      "   micro avg       0.75      0.75      0.75      7955\n",
      "   macro avg       0.81      0.59      0.65      7955\n",
      "weighted avg       0.77      0.75      0.74      7955\n",
      "\n",
      "\n",
      "================================================================================\n",
      "L2 penalty\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "LinearSVC(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=None, tol=0.001,\n",
      "     verbose=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train time: 1.914s\n",
      "test time:  0.003s\n",
      "accuracy:   0.796\n",
      "dimensionality: 8285\n",
      "density: 0.322028\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   brazilian       0.77      0.59      0.67        93\n",
      "     british       0.68      0.46      0.55       161\n",
      "cajun_creole       0.76      0.72      0.74       309\n",
      "     chinese       0.80      0.86      0.83       535\n",
      "    filipino       0.76      0.62      0.68       151\n",
      "      french       0.62      0.69      0.65       529\n",
      "       greek       0.81      0.72      0.77       235\n",
      "      indian       0.88      0.91      0.89       601\n",
      "       irish       0.65      0.45      0.53       133\n",
      "     italian       0.83      0.88      0.86      1568\n",
      "    jamaican       0.82      0.71      0.76       105\n",
      "    japanese       0.84      0.70      0.77       284\n",
      "      korean       0.82      0.80      0.81       166\n",
      "     mexican       0.90      0.93      0.91      1288\n",
      "    moroccan       0.80      0.79      0.79       164\n",
      "     russian       0.61      0.46      0.52        98\n",
      " southern_us       0.71      0.80      0.76       864\n",
      "     spanish       0.69      0.48      0.57       198\n",
      "        thai       0.79      0.79      0.79       308\n",
      "  vietnamese       0.72      0.60      0.66       165\n",
      "\n",
      "   micro avg       0.80      0.80      0.80      7955\n",
      "   macro avg       0.76      0.70      0.72      7955\n",
      "weighted avg       0.79      0.80      0.79      7955\n",
      "\n",
      "\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
      "       early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
      "       l1_ratio=0.15, learning_rate='optimal', loss='hinge', max_iter=50,\n",
      "       n_iter=None, n_iter_no_change=5, n_jobs=None, penalty='l2',\n",
      "       power_t=0.5, random_state=2019, shuffle=True, tol=None,\n",
      "       validation_fraction=0.1, verbose=0, warm_start=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ncp/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train time: 2.473s\n",
      "test time:  0.003s\n",
      "accuracy:   0.781\n",
      "dimensionality: 8285\n",
      "density: 0.150398\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   brazilian       0.74      0.49      0.59        93\n",
      "     british       0.69      0.27      0.39       161\n",
      "cajun_creole       0.76      0.70      0.73       309\n",
      "     chinese       0.78      0.88      0.83       535\n",
      "    filipino       0.74      0.50      0.60       151\n",
      "      french       0.65      0.63      0.64       529\n",
      "       greek       0.82      0.71      0.76       235\n",
      "      indian       0.83      0.91      0.87       601\n",
      "       irish       0.72      0.32      0.45       133\n",
      "     italian       0.79      0.91      0.85      1568\n",
      "    jamaican       0.82      0.68      0.74       105\n",
      "    japanese       0.82      0.68      0.74       284\n",
      "      korean       0.79      0.72      0.75       166\n",
      "     mexican       0.89      0.93      0.91      1288\n",
      "    moroccan       0.80      0.76      0.78       164\n",
      "     russian       0.60      0.42      0.49        98\n",
      " southern_us       0.67      0.79      0.73       864\n",
      "     spanish       0.74      0.42      0.54       198\n",
      "        thai       0.76      0.81      0.78       308\n",
      "  vietnamese       0.81      0.50      0.62       165\n",
      "\n",
      "   micro avg       0.78      0.78      0.78      7955\n",
      "   macro avg       0.76      0.65      0.69      7955\n",
      "weighted avg       0.78      0.78      0.77      7955\n",
      "\n",
      "\n",
      "================================================================================\n",
      "L1 penalty\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "LinearSVC(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l1', random_state=None, tol=0.001,\n",
      "     verbose=0)\n",
      "train time: 16.402s\n",
      "test time:  0.003s\n",
      "accuracy:   0.795\n",
      "dimensionality: 8285\n",
      "density: 0.067610\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   brazilian       0.76      0.58      0.66        93\n",
      "     british       0.70      0.45      0.55       161\n",
      "cajun_creole       0.75      0.71      0.73       309\n",
      "     chinese       0.80      0.87      0.83       535\n",
      "    filipino       0.72      0.58      0.64       151\n",
      "      french       0.62      0.68      0.65       529\n",
      "       greek       0.81      0.72      0.76       235\n",
      "      indian       0.87      0.91      0.89       601\n",
      "       irish       0.67      0.44      0.53       133\n",
      "     italian       0.83      0.88      0.85      1568\n",
      "    jamaican       0.82      0.71      0.77       105\n",
      "    japanese       0.86      0.70      0.77       284\n",
      "      korean       0.82      0.79      0.80       166\n",
      "     mexican       0.91      0.93      0.92      1288\n",
      "    moroccan       0.82      0.80      0.81       164\n",
      "     russian       0.62      0.44      0.51        98\n",
      " southern_us       0.70      0.80      0.75       864\n",
      "     spanish       0.67      0.48      0.56       198\n",
      "        thai       0.80      0.80      0.80       308\n",
      "  vietnamese       0.73      0.58      0.65       165\n",
      "\n",
      "   micro avg       0.80      0.80      0.80      7955\n",
      "   macro avg       0.76      0.69      0.72      7955\n",
      "weighted avg       0.79      0.80      0.79      7955\n",
      "\n",
      "\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
      "       early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
      "       l1_ratio=0.15, learning_rate='optimal', loss='hinge', max_iter=50,\n",
      "       n_iter=None, n_iter_no_change=5, n_jobs=None, penalty='l1',\n",
      "       power_t=0.5, random_state=2019, shuffle=True, tol=None,\n",
      "       validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "train time: 5.531s\n",
      "test time:  0.003s\n",
      "accuracy:   0.732\n",
      "dimensionality: 8285\n",
      "density: 0.011503\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   brazilian       0.15      0.35      0.21        93\n",
      "     british       0.93      0.09      0.16       161\n",
      "cajun_creole       0.74      0.66      0.69       309\n",
      "     chinese       0.72      0.87      0.79       535\n",
      "    filipino       0.82      0.21      0.34       151\n",
      "      french       0.63      0.49      0.55       529\n",
      "       greek       0.78      0.69      0.73       235\n",
      "      indian       0.82      0.90      0.86       601\n",
      "       irish       0.67      0.23      0.35       133\n",
      "     italian       0.76      0.90      0.82      1568\n",
      "    jamaican       0.76      0.55      0.64       105\n",
      "    japanese       0.60      0.65      0.62       284\n",
      "      korean       0.79      0.64      0.71       166\n",
      "     mexican       0.88      0.92      0.90      1288\n",
      "    moroccan       0.81      0.69      0.74       164\n",
      "     russian       0.50      0.14      0.22        98\n",
      " southern_us       0.64      0.78      0.70       864\n",
      "     spanish       0.56      0.19      0.28       198\n",
      "        thai       0.71      0.82      0.76       308\n",
      "  vietnamese       0.76      0.25      0.37       165\n",
      "\n",
      "   micro avg       0.73      0.73      0.73      7955\n",
      "   macro avg       0.70      0.55      0.57      7955\n",
      "weighted avg       0.74      0.73      0.71      7955\n",
      "\n",
      "\n",
      "================================================================================\n",
      "Elastic-Net penalty\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
      "       early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
      "       l1_ratio=0.15, learning_rate='optimal', loss='hinge', max_iter=50,\n",
      "       n_iter=None, n_iter_no_change=5, n_jobs=None, penalty='elasticnet',\n",
      "       power_t=0.5, random_state=2019, shuffle=True, tol=None,\n",
      "       validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "train time: 7.095s\n",
      "test time:  0.003s\n",
      "accuracy:   0.775\n",
      "dimensionality: 8285\n",
      "density: 0.058950\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   brazilian       0.60      0.43      0.50        93\n",
      "     british       0.54      0.20      0.30       161\n",
      "cajun_creole       0.75      0.69      0.72       309\n",
      "     chinese       0.77      0.88      0.82       535\n",
      "    filipino       0.73      0.47      0.57       151\n",
      "      french       0.64      0.62      0.63       529\n",
      "       greek       0.81      0.71      0.76       235\n",
      "      indian       0.83      0.92      0.87       601\n",
      "       irish       0.81      0.29      0.43       133\n",
      "     italian       0.79      0.91      0.84      1568\n",
      "    jamaican       0.84      0.68      0.75       105\n",
      "    japanese       0.85      0.67      0.75       284\n",
      "      korean       0.80      0.72      0.76       166\n",
      "     mexican       0.89      0.93      0.91      1288\n",
      "    moroccan       0.80      0.75      0.78       164\n",
      "     russian       0.61      0.34      0.43        98\n",
      " southern_us       0.66      0.78      0.72       864\n",
      "     spanish       0.72      0.39      0.50       198\n",
      "        thai       0.76      0.83      0.79       308\n",
      "  vietnamese       0.81      0.48      0.61       165\n",
      "\n",
      "   micro avg       0.78      0.78      0.78      7955\n",
      "   macro avg       0.75      0.63      0.67      7955\n",
      "weighted avg       0.77      0.78      0.76      7955\n",
      "\n",
      "\n",
      "================================================================================\n",
      "NearestCentroid (aka Rocchio classifier)\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "NearestCentroid(metric='euclidean', shrink_threshold=None)\n",
      "train time: 0.048s\n",
      "test time:  0.004s\n",
      "accuracy:   0.617\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   brazilian       0.21      0.51      0.30        93\n",
      "     british       0.17      0.51      0.26       161\n",
      "cajun_creole       0.53      0.73      0.62       309\n",
      "     chinese       0.81      0.71      0.76       535\n",
      "    filipino       0.33      0.54      0.41       151\n",
      "      french       0.40      0.44      0.42       529\n",
      "       greek       0.55      0.65      0.60       235\n",
      "      indian       0.87      0.71      0.78       601\n",
      "       irish       0.35      0.59      0.44       133\n",
      "     italian       0.89      0.62      0.73      1568\n",
      "    jamaican       0.54      0.53      0.54       105\n",
      "    japanese       0.81      0.57      0.67       284\n",
      "      korean       0.53      0.63      0.58       166\n",
      "     mexican       0.94      0.75      0.84      1288\n",
      "    moroccan       0.52      0.79      0.63       164\n",
      "     russian       0.30      0.45      0.36        98\n",
      " southern_us       0.68      0.42      0.52       864\n",
      "     spanish       0.23      0.64      0.34       198\n",
      "        thai       0.74      0.59      0.66       308\n",
      "  vietnamese       0.46      0.62      0.53       165\n",
      "\n",
      "   micro avg       0.62      0.62      0.62      7955\n",
      "   macro avg       0.54      0.60      0.55      7955\n",
      "weighted avg       0.71      0.62      0.64      7955\n",
      "\n",
      "\n",
      "================================================================================\n",
      "Naive Bayes\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "MultinomialNB(alpha=0.01, class_prior=None, fit_prior=True)\n",
      "train time: 0.130s\n",
      "test time:  0.003s\n",
      "accuracy:   0.739\n",
      "dimensionality: 8285\n",
      "density: 1.000000\n",
      "classification report:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   brazilian       0.81      0.45      0.58        93\n",
      "     british       0.53      0.30      0.39       161\n",
      "cajun_creole       0.69      0.64      0.66       309\n",
      "     chinese       0.72      0.88      0.80       535\n",
      "    filipino       0.79      0.47      0.59       151\n",
      "      french       0.57      0.57      0.57       529\n",
      "       greek       0.87      0.54      0.67       235\n",
      "      indian       0.83      0.89      0.86       601\n",
      "       irish       0.71      0.26      0.38       133\n",
      "     italian       0.75      0.88      0.81      1568\n",
      "    jamaican       0.88      0.50      0.63       105\n",
      "    japanese       0.89      0.62      0.73       284\n",
      "      korean       0.87      0.62      0.73       166\n",
      "     mexican       0.86      0.89      0.88      1288\n",
      "    moroccan       0.81      0.66      0.73       164\n",
      "     russian       0.68      0.31      0.42        98\n",
      " southern_us       0.57      0.75      0.65       864\n",
      "     spanish       0.72      0.36      0.48       198\n",
      "        thai       0.72      0.76      0.74       308\n",
      "  vietnamese       0.73      0.50      0.59       165\n",
      "\n",
      "   micro avg       0.74      0.74      0.74      7955\n",
      "   macro avg       0.75      0.59      0.64      7955\n",
      "weighted avg       0.75      0.74      0.73      7955\n",
      "\n",
      "\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "BernoulliNB(alpha=0.01, binarize=0.0, class_prior=None, fit_prior=True)\n",
      "train time: 0.132s\n",
      "test time:  0.009s\n",
      "accuracy:   0.724\n",
      "dimensionality: 8285\n",
      "density: 1.000000\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   brazilian       0.44      0.54      0.49        93\n",
      "     british       0.28      0.55      0.37       161\n",
      "cajun_creole       0.60      0.74      0.66       309\n",
      "     chinese       0.81      0.79      0.80       535\n",
      "    filipino       0.55      0.62      0.58       151\n",
      "      french       0.55      0.50      0.53       529\n",
      "       greek       0.68      0.69      0.69       235\n",
      "      indian       0.89      0.86      0.87       601\n",
      "       irish       0.51      0.56      0.53       133\n",
      "     italian       0.87      0.76      0.81      1568\n",
      "    jamaican       0.75      0.62      0.68       105\n",
      "    japanese       0.76      0.65      0.70       284\n",
      "      korean       0.74      0.75      0.74       166\n",
      "     mexican       0.93      0.85      0.89      1288\n",
      "    moroccan       0.72      0.74      0.73       164\n",
      "     russian       0.37      0.48      0.42        98\n",
      " southern_us       0.64      0.69      0.67       864\n",
      "     spanish       0.41      0.59      0.48       198\n",
      "        thai       0.77      0.70      0.73       308\n",
      "  vietnamese       0.57      0.56      0.56       165\n",
      "\n",
      "   micro avg       0.72      0.72      0.72      7955\n",
      "   macro avg       0.64      0.66      0.65      7955\n",
      "weighted avg       0.75      0.72      0.73      7955\n",
      "\n",
      "\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "ComplementNB(alpha=0.1, class_prior=None, fit_prior=True, norm=False)\n",
      "train time: 0.130s\n",
      "test time:  0.003s\n",
      "accuracy:   0.701\n",
      "dimensionality: 8285\n",
      "density: 1.000000\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   brazilian       0.75      0.44      0.55        93\n",
      "     british       0.59      0.15      0.24       161\n",
      "cajun_creole       0.68      0.61      0.64       309\n",
      "     chinese       0.59      0.90      0.72       535\n",
      "    filipino       0.78      0.24      0.37       151\n",
      "      french       0.61      0.48      0.54       529\n",
      "       greek       0.81      0.52      0.63       235\n",
      "      indian       0.72      0.91      0.80       601\n",
      "       irish       0.71      0.23      0.34       133\n",
      "     italian       0.73      0.89      0.81      1568\n",
      "    jamaican       0.79      0.44      0.56       105\n",
      "    japanese       0.83      0.67      0.74       284\n",
      "      korean       0.77      0.36      0.49       166\n",
      "     mexican       0.83      0.91      0.87      1288\n",
      "    moroccan       0.78      0.46      0.58       164\n",
      "     russian       0.63      0.19      0.30        98\n",
      " southern_us       0.55      0.74      0.63       864\n",
      "     spanish       0.67      0.18      0.28       198\n",
      "        thai       0.63      0.61      0.62       308\n",
      "  vietnamese       0.72      0.21      0.32       165\n",
      "\n",
      "   micro avg       0.70      0.70      0.70      7955\n",
      "   macro avg       0.71      0.51      0.55      7955\n",
      "weighted avg       0.71      0.70      0.68      7955\n",
      "\n",
      "\n",
      "================================================================================\n",
      "LinearSVC with L1-based feature selection\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "Pipeline(memory=None,\n",
      "     steps=[('feature_selection', SelectFromModel(estimator=LinearSVC(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l1', random_state=2019, tol=0.001,\n",
      "     verbose=0),\n",
      "        max_features=None, no...ax_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=2019, tol=0.0001,\n",
      "     verbose=0))])\n",
      "train time: 16.891s\n",
      "test time:  0.006s\n",
      "accuracy:   0.797\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   brazilian       0.77      0.59      0.67        93\n",
      "     british       0.67      0.46      0.54       161\n",
      "cajun_creole       0.77      0.72      0.74       309\n",
      "     chinese       0.80      0.86      0.83       535\n",
      "    filipino       0.75      0.61      0.67       151\n",
      "      french       0.63      0.69      0.65       529\n",
      "       greek       0.82      0.72      0.77       235\n",
      "      indian       0.87      0.91      0.89       601\n",
      "       irish       0.65      0.45      0.53       133\n",
      "     italian       0.83      0.89      0.86      1568\n",
      "    jamaican       0.82      0.71      0.77       105\n",
      "    japanese       0.84      0.70      0.76       284\n",
      "      korean       0.82      0.80      0.81       166\n",
      "     mexican       0.90      0.92      0.91      1288\n",
      "    moroccan       0.80      0.78      0.79       164\n",
      "     russian       0.62      0.46      0.53        98\n",
      " southern_us       0.71      0.81      0.76       864\n",
      "     spanish       0.69      0.48      0.57       198\n",
      "        thai       0.79      0.79      0.79       308\n",
      "  vietnamese       0.72      0.61      0.66       165\n",
      "\n",
      "   micro avg       0.80      0.80      0.80      7955\n",
      "   macro avg       0.76      0.70      0.73      7955\n",
      "weighted avg       0.79      0.80      0.79      7955\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "RANDOM_ST = 2019\n",
    "\n",
    "target_names = ['brazilian', 'british', 'cajun_creole', 'chinese', 'filipino', 'french', 'greek',\n",
    "           'indian', 'irish', 'italian', 'jamaican', 'japanese', 'korean', 'mexican', 'moroccan',\n",
    "           'russian', 'southern_us', 'spanish', 'thai', 'vietnamese']\n",
    "\n",
    "results = []\n",
    "for clf, name in (\n",
    "        (RidgeClassifier(tol=1e-2, solver=\"sag\",random_state=RANDOM_ST), \"Ridge Classifier\"),\n",
    "        (Perceptron(max_iter=50, tol=1e-3,random_state=RANDOM_ST), \"Perceptron\"),\n",
    "        (PassiveAggressiveClassifier(max_iter=50, tol=1e-3,random_state=RANDOM_ST), \"Passive-Aggressive\"),\n",
    "        (KNeighborsClassifier(n_neighbors=10), \"kNN\"),\n",
    "        (RandomForestClassifier(n_estimators=100,random_state=RANDOM_ST), \"Random forest\")):\n",
    "    print('=' * 80)\n",
    "    print(name)\n",
    "    results.append(benchmark(clf))\n",
    "    \n",
    "for penalty in [\"l2\", \"l1\"]:\n",
    "    print('=' * 80)\n",
    "    print(\"%s penalty\" % penalty.upper())\n",
    "    # Train Liblinear model\n",
    "    results.append(benchmark(LinearSVC(penalty=penalty, dual=False, tol=1e-3)))\n",
    "\n",
    "    # Train SGD model\n",
    "    results.append(benchmark(SGDClassifier(alpha=.0001, max_iter=50,penalty=penalty,random_state=RANDOM_ST)))\n",
    "\n",
    "# Train SGD with Elastic Net penalty\n",
    "print('=' * 80)\n",
    "print(\"Elastic-Net penalty\")\n",
    "results.append(benchmark(SGDClassifier(alpha=.0001, max_iter=50,penalty=\"elasticnet\",random_state=RANDOM_ST)))\n",
    "\n",
    "# Train NearestCentroid without threshold\n",
    "print('=' * 80)\n",
    "print(\"NearestCentroid (aka Rocchio classifier)\")\n",
    "results.append(benchmark(NearestCentroid()))\n",
    "\n",
    "# Train sparse Naive Bayes classifiers\n",
    "print('=' * 80)\n",
    "print(\"Naive Bayes\")\n",
    "results.append(benchmark(MultinomialNB(alpha=.01)))\n",
    "results.append(benchmark(BernoulliNB(alpha=.01)))\n",
    "results.append(benchmark(ComplementNB(alpha=.1)))\n",
    "\n",
    "print('=' * 80)\n",
    "print(\"LinearSVC with L1-based feature selection\")\n",
    "# The smaller C, the stronger the regularization.\n",
    "# The more regularization, the more sparsity.\n",
    "results.append(benchmark(Pipeline([('feature_selection', SelectFromModel(LinearSVC(penalty=\"l1\", dual=False,tol=1e-3,random_state=RANDOM_ST))),\n",
    "  ('classification', LinearSVC(penalty=\"l2\",random_state=RANDOM_ST))])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________________________________\n",
      "Training: \n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
      "       max_depth=25, min_child_weight=1, missing=None, n_estimators=400,\n",
      "       n_jobs=1, nthread=None, objective='binary:logistic',\n",
      "       random_state=2019, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "       seed=None, silent=True, subsample=1)\n",
      "train time: 2393.403s\n",
      "test time:  20.284s\n",
      "accuracy:   0.791\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   brazilian       0.86      0.60      0.71        93\n",
      "     british       0.74      0.42      0.54       161\n",
      "cajun_creole       0.79      0.69      0.74       309\n",
      "     chinese       0.80      0.86      0.83       535\n",
      "    filipino       0.71      0.58      0.64       151\n",
      "      french       0.62      0.64      0.63       529\n",
      "       greek       0.81      0.70      0.75       235\n",
      "      indian       0.86      0.91      0.88       601\n",
      "       irish       0.72      0.51      0.60       133\n",
      "     italian       0.79      0.90      0.85      1568\n",
      "    jamaican       0.85      0.67      0.75       105\n",
      "    japanese       0.84      0.70      0.76       284\n",
      "      korean       0.84      0.64      0.73       166\n",
      "     mexican       0.90      0.93      0.92      1288\n",
      "    moroccan       0.88      0.74      0.81       164\n",
      "     russian       0.67      0.37      0.47        98\n",
      " southern_us       0.70      0.80      0.75       864\n",
      "     spanish       0.66      0.48      0.56       198\n",
      "        thai       0.81      0.81      0.81       308\n",
      "  vietnamese       0.69      0.61      0.65       165\n",
      "\n",
      "   micro avg       0.79      0.79      0.79      7955\n",
      "   macro avg       0.78      0.68      0.72      7955\n",
      "weighted avg       0.79      0.79      0.79      7955\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "import xgboost as xgb\n",
    "\n",
    "# xgb  <- xgboost(xgbmat, max.depth = 25, \n",
    "# eta = 0.3, nround = 200, objective = \"multi:softmax\", num_class = 20)\n",
    "# https://www.kaggle.com/mohdatir/xgboost\n",
    "\n",
    "results.append(benchmark(xgb.XGBClassifier(max_depth=25, n_estimators=400, random_state=RANDOM_ST)))\n",
    "\n",
    "# objective='binary:logistic'  objective issue : \n",
    "# https://stackoverflow.com/questions/39386966/multiclass-classification-in-xgboost-python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('RidgeClassifier', 0.7637963544940289, 2.6992623805999756, 0.0033826828002929688), ('Perceptron', 0.732872407291012, 0.3552682399749756, 0.0034515857696533203), ('PassiveAggressiveClassifier', 0.7654305468258956, 0.7697908878326416, 0.003209352493286133), ('KNeighborsClassifier', 0.7532369578881207, 0.04427742958068848, 10.02836012840271), ('RandomForestClassifier', 0.7539912005028284, 44.483813762664795, 0.31233739852905273), ('LinearSVC', 0.7962287869264614, 1.9141135215759277, 0.0031328201293945312), ('SGDClassifier', 0.7813953488372093, 2.4734082221984863, 0.003304719924926758), ('LinearSVC', 0.7950974230043998, 16.402331829071045, 0.0032787322998046875), ('SGDClassifier', 0.7317410433689503, 5.530510663986206, 0.0032744407653808594), ('SGDClassifier', 0.7751099937146448, 7.094851493835449, 0.0032968521118164062), ('NearestCentroid', 0.6173475801382778, 0.0479276180267334, 0.00380706787109375), ('MultinomialNB', 0.7386549340037712, 0.12987112998962402, 0.002753019332885742), ('BernoulliNB', 0.7236957888120679, 0.13193821907043457, 0.009018421173095703), ('ComplementNB', 0.7008170961659334, 0.12952232360839844, 0.0026445388793945312), ('Pipeline', 0.7967316153362665, 16.891195058822632, 0.005513429641723633), ('XGBClassifier', 0.7910747957259585, 2393.403423309326, 20.284092664718628)]\n"
     ]
    }
   ],
   "source": [
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = sorted(results,  key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "indices = np.arange(len(results))\n",
    "\n",
    "results = [[x[i] for x in results] for i in range(4)]\n",
    "\n",
    "clf_names, score, training_time, test_time = results\n",
    "training_time = np.array(training_time) / np.max(training_time)\n",
    "test_time = np.array(test_time) / np.max(test_time)\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.title(\"Score\")\n",
    "plt.barh(indices, score, .2, label=\"score\", color='navy')\n",
    "plt.barh(indices + .3, training_time, .2, label=\"training time\",\n",
    "         color='c')\n",
    "plt.barh(indices + .6, test_time, .2, label=\"test time\", color='darkorange')\n",
    "plt.yticks(())\n",
    "plt.legend(loc='best')\n",
    "plt.subplots_adjust(left=.25)\n",
    "plt.subplots_adjust(top=.95)\n",
    "plt.subplots_adjust(bottom=.05)\n",
    "\n",
    "for i, c in zip(indices, clf_names):\n",
    "    plt.text(-.3, i, c)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7510763670647391\n"
     ]
    }
   ],
   "source": [
    "print(np.average(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7967316153362665\n"
     ]
    }
   ],
   "source": [
    "print(np.max(score))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
